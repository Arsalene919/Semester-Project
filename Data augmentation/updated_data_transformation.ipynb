{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1mfj22KO44Y",
        "outputId": "b5c337f7-e5a7-4264-f126-e06eb591fc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data has been saved to /content/augmented_train_subtask2.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# File paths\n",
        "input_file_path = '/content/generated_examples (2).txt'\n",
        "output_file_path = '/content/augmented_train_subtask2.csv'\n",
        "\n",
        "# Read the text file\n",
        "with open(input_file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Initialize lists to store the extracted data\n",
        "domains = []\n",
        "text_pairs = []\n",
        "\n",
        "# Variables to hold current domain and causal pairs\n",
        "current_domain = None\n",
        "current_pairs = []\n",
        "\n",
        "# Process each line in the file\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if line.startswith('</s>'):\n",
        "        # If we reach a new domain section, save the previous data if any\n",
        "        if current_domain and current_pairs:\n",
        "            domains.append(current_domain)\n",
        "            text_pairs.append(' '.join(current_pairs))\n",
        "            current_pairs = []\n",
        "    elif line.startswith('in the domain of'):\n",
        "        # Extract the domain\n",
        "        current_domain = line.replace('in the domain of', '').strip()\n",
        "    elif line:\n",
        "        # Collect the causal text pairs\n",
        "        current_pairs.append(line)\n",
        "\n",
        "# Add the last collected domain and pairs if any\n",
        "if current_domain and current_pairs:\n",
        "    domains.append(current_domain)\n",
        "    text_pairs.append(' '.join(current_pairs))\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame({\n",
        "    'num_rs': domains,\n",
        "    'text_w_pairs': text_pairs\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a new CSV file with swapped columns\n",
        "df.to_csv(output_file_path, index=False, columns=['text_w_pairs', 'num_rs'])\n",
        "\n",
        "print(f\"Processed data has been saved to {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTDrhLuYO44c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reading the given CSV file\n",
        "df = pd.read_csv(\"/content/augmented_train_subtask2.csv\")\n",
        "\n",
        "# Adding a new column 'sent_id' starting from 10000 and incrementing by 1\n",
        "df['sent_id'] = range(10000, 10000 + len(df))\n",
        "\n",
        "# Adding a new column 'corpus' with constant value 'cnc'\n",
        "df['corpus'] = 'cnc'\n",
        "\n",
        "# Adding a new column 'eg_id' with constant value 0\n",
        "df['eg_id'] = 0\n",
        "\n",
        "# Adding a new column 'doc_id' with values 'train_1000_10000' where 'train_' is constant, and the other two values are incremented by 1\n",
        "df['doc_id'] = [f'train_{i}_{j}' for i, j in zip(range(1000, 1000 + len(df)), range(10000, 10000 + len(df)))]\n",
        "\n",
        "# Adding a new column 'index' with values based on variables i, j, k\n",
        "df['index'] = [f'cnc_train_{i}_{j}_{k}_10' for i, j, k in zip(range(100, 100 + len(df)), range(1000, 1000 + len(df)), range(10000, 10000 + len(df)))]\n",
        "\n",
        "# Reordering columns\n",
        "df = df[['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text_w_pairs', 'num_rs']]\n",
        "\n",
        "# Store the DataFrame into  CSV file with the added 'sent_id' column\n",
        "df.to_csv('/content/augmented_train_subtask2.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_En9HfjaO44d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Reading the given CSV file\n",
        "df = pd.read_csv(\"/content/augmented_train_subtask2.csv\")\n",
        "\n",
        "# Adding a new column 'text' with the same data as 'causal_text_w_pairs' but without <arg1>, <arg0>, <sig0> tags\n",
        "df['text'] = df['text_w_pairs'].apply(lambda x: re.sub(r'<(/?ARG[01]|/?SIG0)>', '', x))\n",
        "\n",
        "# Remove square brackets from the 'text' column sentences\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'[\\[\\]]', '', x))\n",
        "# Reordering columns\n",
        "df = df[['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text', 'text_w_pairs', 'num_rs']]\n",
        "\n",
        "# Store the DataFrame into a CSV file with the added columns\n",
        "df.to_csv('/content/augmented_train_subtask2.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etfkjDFmO44d"
      },
      "outputs": [],
      "source": [
        "# Add the 'has_causality' column\n",
        "df['num_rs'] = df['text_w_pairs'].apply(lambda x: '1' if x else '0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpbXf4JFO44e"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('/content/train_subtask2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZ_K6p1O44e",
        "outputId": "1778825d-ba36-40a9-e675-10dd2c9fe693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data has been saved to None\n"
          ]
        }
      ],
      "source": [
        "df3 = pd.concat([df2, df], ignore_index=True)\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file\n",
        "output_csv_path = df3.to_csv('/content/train_subtask2_augmented.csv', index=False)\n",
        "\n",
        "print(f\"Processed data has been saved to {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH1RPsmXO44e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fadba2fc",
        "outputId": "01547712-70fd-414d-af4c-74169ae6ed13"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/augmented_train_subtask2.csv'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the CSV file to understand its structure\n",
        "csv_file_path = '/content/train_subtask2.csv'\n",
        "csv_data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Load the text file to understand its structure\n",
        "text_file_path = '/content/generated_examples (2).txt'\n",
        "\n",
        "with open(text_file_path, 'r') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "# Define a function to parse the text file and extract data\n",
        "def parse_text_data(text):\n",
        "    sections = re.split(r'</s>', text)\n",
        "    data = []\n",
        "\n",
        "    doc_id_counter = 1\n",
        "\n",
        "    for section in sections:\n",
        "        section = section.strip()\n",
        "        if not section:\n",
        "            continue\n",
        "\n",
        "        domain_match = re.search(r'in the domain of (.+)', section)\n",
        "        if not domain_match:\n",
        "            continue\n",
        "\n",
        "        domain = domain_match.group(1).strip()\n",
        "        doc_id = f\"{domain.replace(' ', '_').lower()}_{doc_id_counter}\"\n",
        "        doc_id_counter += 1\n",
        "\n",
        "        events = re.findall(r'<ARG0>(.*?)</ARG0>\\s*<SIG0>(.*?)</SIG0>\\s*<ARG1>(.*?)</ARG1>', section, re.DOTALL)\n",
        "        for sent_id, (arg0, sig0, arg1) in enumerate(events, 1):\n",
        "            eg_id = sent_id - 1\n",
        "            text_w_pairs = f\"<ARG0>{arg0.strip()}</ARG0> <SIG0>{sig0.strip()}</SIG0> <ARG1>{arg1.strip()}</ARG1>\"\n",
        "            seq_label = 1  # Placeholder value, as original labels are not provided\n",
        "            pair_label = 1  # Placeholder value, as original labels are not provided\n",
        "            context = None\n",
        "            num_sents = 1\n",
        "\n",
        "            data.append([domain, doc_id, sent_id, eg_id, text_w_pairs, seq_label, pair_label, context, num_sents])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Parse the text data\n",
        "parsed_data = parse_text_data(text_data)\n",
        "\n",
        "# Create a DataFrame with the required columns\n",
        "columns = ['corpus', 'doc_id', 'sent_id', 'eg_id', 'text_w_pairs', 'seq_label', 'pair_label', 'context', 'num_sents']\n",
        "df = pd.DataFrame(parsed_data, columns=columns)\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "output_csv_path = '/content/augmented_train_subtask2.csv'\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "output_csv_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtU19xNLf57L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reading the given CSV file\n",
        "df = pd.read_csv(\"/content/augmented_train_subtask2.csv\")\n",
        "\n",
        "# Adding a new column 'sent_id' starting from 10000 and incrementing by 1\n",
        "df['sent_id'] = range(10000, 10000 + len(df))\n",
        "\n",
        "# Adding a new column 'corpus' with constant value 'cnc'\n",
        "df['corpus'] = 'cnc'\n",
        "\n",
        "# Adding a new column 'eg_id' with constant value 0\n",
        "df['eg_id'] = 0\n",
        "\n",
        "# Adding a new column 'doc_id' with values 'train_1000_10000' where 'train_' is constant, and the other two values are incremented by 1\n",
        "df['doc_id'] = [f'train_{i}_{j}' for i, j in zip(range(1000, 1000 + len(df)), range(10000, 10000 + len(df)))]\n",
        "\n",
        "# Adding a new column 'index' with values based on variables i, j, k\n",
        "df['index'] = [f'cnc_train_{i}_{j}_{k}_10' for i, j, k in zip(range(100, 100 + len(df)), range(1000, 1000 + len(df)), range(10000, 10000 + len(df)))]\n",
        "\n",
        "# Reordering columns\n",
        "df = df[['corpus', 'doc_id', 'sent_id', 'eg_id','index', 'text_w_pairs', 'seq_label', 'pair_label', 'context', 'num_sents']]\n",
        "\n",
        "# Store the DataFrame into  CSV file with the added 'sent_id' column\n",
        "df.to_csv('/content/augmented_train_subtask2.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2uULT25f5s3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Reading the given CSV file\n",
        "df = pd.read_csv(\"/content/augmented_train_subtask2.csv\")\n",
        "\n",
        "# Adding a new column 'text' with the same data as 'causal_text_w_pairs' but without <arg1>, <arg0>, <sig0> tags\n",
        "df['text'] = df['text_w_pairs'].apply(lambda x: re.sub(r'<(/?ARG[01]|/?SIG0)>', '', x))\n",
        "\n",
        "# Remove square brackets from the 'text' column sentences\n",
        "df['text'] = df['text'].apply(lambda x: re.sub(r'[\\[\\]]', '', x))\n",
        "# Reordering columns\n",
        "df = df[['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text', 'text_w_pairs', 'seq_label', 'pair_label', 'context', 'num_sents']]\n",
        "\n",
        "# Store the DataFrame into a CSV file with the added columns\n",
        "df.to_csv('/content/augmented_train_subtask2.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR4Or8ySgEGT"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('/content/train_subtask2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3sRGcxHgEC2",
        "outputId": "8e08454e-caa3-4952-b680-1d83b55602ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data has been saved to None\n"
          ]
        }
      ],
      "source": [
        "df3 = pd.concat([df2, df], ignore_index=True)\n",
        "\n",
        "# Save the combined DataFrame to a new CSV file\n",
        "output_csv_path = df3.to_csv('/content/combined_data.csv', index=False)\n",
        "\n",
        "print(f\"Processed data has been saved to {output_csv_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
