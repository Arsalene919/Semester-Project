{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2688769b95bb4cf2b0b983b8ccd2fae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8cce8e445614b1781aa06e8955c08d4",
              "IPY_MODEL_d5aa1b0fa71f4449a11ee04ceb082d15",
              "IPY_MODEL_8c2f09851d0f4b3fae9e93a7a94e8322"
            ],
            "layout": "IPY_MODEL_c4905cda5b69457fab2d7f111f94d207"
          }
        },
        "a8cce8e445614b1781aa06e8955c08d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e790ffdf464f92aa3be5eac7156bdd",
            "placeholder": "​",
            "style": "IPY_MODEL_c2370a445228488092b42f30097a861c",
            "value": "config.json: 100%"
          }
        },
        "d5aa1b0fa71f4449a11ee04ceb082d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25a6b7ab345d4388a24b002668dc431b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a797430caf704e17b71d0394a229a390",
            "value": 665
          }
        },
        "8c2f09851d0f4b3fae9e93a7a94e8322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ebae6b37464feba91b913cd9d1c269",
            "placeholder": "​",
            "style": "IPY_MODEL_811361ac804a4e5cb1e7881fbf28c822",
            "value": " 665/665 [00:00&lt;00:00, 41.6kB/s]"
          }
        },
        "c4905cda5b69457fab2d7f111f94d207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e790ffdf464f92aa3be5eac7156bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2370a445228488092b42f30097a861c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25a6b7ab345d4388a24b002668dc431b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a797430caf704e17b71d0394a229a390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ebae6b37464feba91b913cd9d1c269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811361ac804a4e5cb1e7881fbf28c822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec8cd4893f940018ad9b66b1d8f7152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e71c18c37be4c6ea6d623e51fcbfe32",
              "IPY_MODEL_07a4d99efa974d72a03aa77c1a9e3eeb",
              "IPY_MODEL_3bff2ea10b534ad29d44f5fdfb327d3e"
            ],
            "layout": "IPY_MODEL_2158338434c3428d9ee66e0f1cf94030"
          }
        },
        "2e71c18c37be4c6ea6d623e51fcbfe32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e154ef16116945be8c27c8c2e253206a",
            "placeholder": "​",
            "style": "IPY_MODEL_09f55bb480be44669bc4e0043d0a00ba",
            "value": "model.safetensors: 100%"
          }
        },
        "07a4d99efa974d72a03aa77c1a9e3eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35cb37797a714723a528e49f09f7d2ad",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0964c4c3fba941a893bac7adf1eeecb2",
            "value": 548105171
          }
        },
        "3bff2ea10b534ad29d44f5fdfb327d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e97567b6bf74489b41dbbbb907331ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb7cf62ad30452589b5ca6a140b183b",
            "value": " 548M/548M [00:04&lt;00:00, 132MB/s]"
          }
        },
        "2158338434c3428d9ee66e0f1cf94030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e154ef16116945be8c27c8c2e253206a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f55bb480be44669bc4e0043d0a00ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35cb37797a714723a528e49f09f7d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0964c4c3fba941a893bac7adf1eeecb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e97567b6bf74489b41dbbbb907331ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb7cf62ad30452589b5ca6a140b183b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0789560a4142738ac30db98f62bb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2b24fb1ffb94a04891a139c3217779c",
              "IPY_MODEL_79b009f740a94088a813b36e970616a3",
              "IPY_MODEL_564495d04b9a4421a519e69c3db4ffea"
            ],
            "layout": "IPY_MODEL_9b69a116800c458482a0fb955d729dad"
          }
        },
        "c2b24fb1ffb94a04891a139c3217779c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c904aacb5064b7da16a36a5792aa3d3",
            "placeholder": "​",
            "style": "IPY_MODEL_35fbb7c1591f4530bb8a91d0f9f215c5",
            "value": "generation_config.json: 100%"
          }
        },
        "79b009f740a94088a813b36e970616a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_936c58546bdb40728250a34431e526e0",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_821c0a214d3f414eab73e37f1d5c6899",
            "value": 124
          }
        },
        "564495d04b9a4421a519e69c3db4ffea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7e4917d4614d399afb519dfa8f44d0",
            "placeholder": "​",
            "style": "IPY_MODEL_6bd84e659aff46259307840b07d1a3d8",
            "value": " 124/124 [00:00&lt;00:00, 8.36kB/s]"
          }
        },
        "9b69a116800c458482a0fb955d729dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c904aacb5064b7da16a36a5792aa3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35fbb7c1591f4530bb8a91d0f9f215c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "936c58546bdb40728250a34431e526e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821c0a214d3f414eab73e37f1d5c6899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7e4917d4614d399afb519dfa8f44d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bd84e659aff46259307840b07d1a3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "454df127ff134c1cbbe12e6de891394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33b3d7ccd7d0433885fb488cc536b5bc",
              "IPY_MODEL_61fe57dcc8f2462388b64e3a1a947333",
              "IPY_MODEL_8c6cd11294c545a892770cf2ea55f846"
            ],
            "layout": "IPY_MODEL_c4e3126142404b36ad681fcffdd6ceb2"
          }
        },
        "33b3d7ccd7d0433885fb488cc536b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a75e56fa54427ea0754c447e86967b",
            "placeholder": "​",
            "style": "IPY_MODEL_443dc1bc71484c49a721e94ace716cc5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "61fe57dcc8f2462388b64e3a1a947333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_524e86a4e0914b26aa8061c545c4003d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc0194e3b9eb496ebcd46b7504906fcf",
            "value": 26
          }
        },
        "8c6cd11294c545a892770cf2ea55f846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f99edc8e0f04fef8ee87004b5be430b",
            "placeholder": "​",
            "style": "IPY_MODEL_f6390d15dd384839889460e921a72f8e",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.91kB/s]"
          }
        },
        "c4e3126142404b36ad681fcffdd6ceb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a75e56fa54427ea0754c447e86967b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443dc1bc71484c49a721e94ace716cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "524e86a4e0914b26aa8061c545c4003d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0194e3b9eb496ebcd46b7504906fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f99edc8e0f04fef8ee87004b5be430b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6390d15dd384839889460e921a72f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "911ea5b8dc1844c4ba3cfce6821386b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7a21c497e5d4f7ea5efd37beb25b8a1",
              "IPY_MODEL_468812dbab654ebf979f335d0d72c856",
              "IPY_MODEL_e42353a635df4d629e3c5500daf8718e"
            ],
            "layout": "IPY_MODEL_da6ab6e87cd6450c9982de950d24253e"
          }
        },
        "a7a21c497e5d4f7ea5efd37beb25b8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_741e345dc646494d923d8c7203485f89",
            "placeholder": "​",
            "style": "IPY_MODEL_9c66c0164289441a9e0296576fe7e7ff",
            "value": "vocab.json: 100%"
          }
        },
        "468812dbab654ebf979f335d0d72c856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02334ae21b04dc7816d897779a2069f",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3b017a19e014b55af9123bd1184c6f8",
            "value": 1042301
          }
        },
        "e42353a635df4d629e3c5500daf8718e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbfbb1cd65a345e6bea456475f10ed22",
            "placeholder": "​",
            "style": "IPY_MODEL_8e0dabf2c0cb4c4a88fd9c1a663aac0e",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 8.25MB/s]"
          }
        },
        "da6ab6e87cd6450c9982de950d24253e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741e345dc646494d923d8c7203485f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c66c0164289441a9e0296576fe7e7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e02334ae21b04dc7816d897779a2069f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b017a19e014b55af9123bd1184c6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbfbb1cd65a345e6bea456475f10ed22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0dabf2c0cb4c4a88fd9c1a663aac0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cc3a459f1b94208a73348f68d523048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8ed4ae721dc41fb97ec6870ad91c0c6",
              "IPY_MODEL_ea637ddedf5d4fcc8a629ce93670d706",
              "IPY_MODEL_ecfed59cae6c412a82506e8fe23f2089"
            ],
            "layout": "IPY_MODEL_36419db1c4e245d69509a991e9d6238d"
          }
        },
        "a8ed4ae721dc41fb97ec6870ad91c0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27edd1b5cae4c20a800e66fbaf32c16",
            "placeholder": "​",
            "style": "IPY_MODEL_95d08b11a42e44bfaa762cdf76dd74bf",
            "value": "merges.txt: 100%"
          }
        },
        "ea637ddedf5d4fcc8a629ce93670d706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257f6926493d47a5a50854a46c5609f9",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1d920394ee441ba7c2c15b20e1936a",
            "value": 456318
          }
        },
        "ecfed59cae6c412a82506e8fe23f2089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb43f8e73fb44f438481d6afac917671",
            "placeholder": "​",
            "style": "IPY_MODEL_9e62cd4113c94f4fa6125efab412b6e9",
            "value": " 456k/456k [00:00&lt;00:00, 2.42MB/s]"
          }
        },
        "36419db1c4e245d69509a991e9d6238d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27edd1b5cae4c20a800e66fbaf32c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d08b11a42e44bfaa762cdf76dd74bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "257f6926493d47a5a50854a46c5609f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1d920394ee441ba7c2c15b20e1936a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb43f8e73fb44f438481d6afac917671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e62cd4113c94f4fa6125efab412b6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf644a1bac14a928f7300cf4d160420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_896b2a6fc14e436aa77e24c4f4e0bdea",
              "IPY_MODEL_c4f3929f5179400498a21b9d58e7b375",
              "IPY_MODEL_683d6301bc1944aeb96146b37f090c9c"
            ],
            "layout": "IPY_MODEL_41f1b95c343041ce9cb24cd58307dc4a"
          }
        },
        "896b2a6fc14e436aa77e24c4f4e0bdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc75d8c42884362a8bff7148570a31b",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb14a355b5c4e21851b2cdf012560e7",
            "value": "tokenizer.json: 100%"
          }
        },
        "c4f3929f5179400498a21b9d58e7b375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2377078535eb4e499c0b9ae01ea3f485",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10ed04e8bf1b4bf3863d4da6ad528f4e",
            "value": 1355256
          }
        },
        "683d6301bc1944aeb96146b37f090c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d46c0ba8244af7890ed4e2a1026629",
            "placeholder": "​",
            "style": "IPY_MODEL_f140f6bba48844839debf278dea4e59d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 26.7MB/s]"
          }
        },
        "41f1b95c343041ce9cb24cd58307dc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc75d8c42884362a8bff7148570a31b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb14a355b5c4e21851b2cdf012560e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2377078535eb4e499c0b9ae01ea3f485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ed04e8bf1b4bf3863d4da6ad528f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10d46c0ba8244af7890ed4e2a1026629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f140f6bba48844839debf278dea4e59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3525eda754364f6986d84f9b5c149b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08c4581588a34aaca89a8ed5d8e333e5",
              "IPY_MODEL_bec973caa7e24090a4fe75f569835c56",
              "IPY_MODEL_3c2f8556fab9447e8a6745e878ca9511"
            ],
            "layout": "IPY_MODEL_be3ce4a27dc24d9a9282696ba2b02826"
          }
        },
        "08c4581588a34aaca89a8ed5d8e333e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad425b2d5e684deaa54dee0d6cf975a5",
            "placeholder": "​",
            "style": "IPY_MODEL_d3da4f087b7846f1bf04ab515c1e1d80",
            "value": "Fetching 13 files: 100%"
          }
        },
        "bec973caa7e24090a4fe75f569835c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8350ae4e0a134cbc8685d64036ac2a53",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_301f296826fd4d549964a00567c4d472",
            "value": 13
          }
        },
        "3c2f8556fab9447e8a6745e878ca9511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76de96db57a4e548880154c0d3d4448",
            "placeholder": "​",
            "style": "IPY_MODEL_e74d53665bc748f4bb731f120bdf69d1",
            "value": " 13/13 [00:00&lt;00:00, 806.08it/s]"
          }
        },
        "be3ce4a27dc24d9a9282696ba2b02826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad425b2d5e684deaa54dee0d6cf975a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3da4f087b7846f1bf04ab515c1e1d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8350ae4e0a134cbc8685d64036ac2a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301f296826fd4d549964a00567c4d472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c76de96db57a4e548880154c0d3d4448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74d53665bc748f4bb731f120bdf69d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c211f0507ef44093ad75aec6ab9ebef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaa019be5a374e0387fcc5674f3481e5",
              "IPY_MODEL_4728d058bc8d43b9afae05fb043ef8b0",
              "IPY_MODEL_6bb986b13f6b4b04a673a50875fea56e"
            ],
            "layout": "IPY_MODEL_1a66927ff51a455da1b10daa48262f1e"
          }
        },
        "aaa019be5a374e0387fcc5674f3481e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5a186e393743d296a89e6ebfc2c842",
            "placeholder": "​",
            "style": "IPY_MODEL_aca9ed7124c345c7a79d967991fb827e",
            "value": "Loading checkpoint shards:  25%"
          }
        },
        "4728d058bc8d43b9afae05fb043ef8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69c2a2d406d44559bcc7f8209f7ee08",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da6ace86c2b04ea1b051720ad785fd05",
            "value": 3
          }
        },
        "6bb986b13f6b4b04a673a50875fea56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3326ff441348bbbaae6aa2c953261e",
            "placeholder": "​",
            "style": "IPY_MODEL_ced3ea08f5be4c4ea830a50de8a3dc85",
            "value": " 2/8 [00:18&lt;00:56,  9.42s/it]"
          }
        },
        "1a66927ff51a455da1b10daa48262f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5a186e393743d296a89e6ebfc2c842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca9ed7124c345c7a79d967991fb827e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d69c2a2d406d44559bcc7f8209f7ee08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da6ace86c2b04ea1b051720ad785fd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c3326ff441348bbbaae6aa2c953261e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced3ea08f5be4c4ea830a50de8a3dc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7f287381714318aaeb86656a2436ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e87c2d88cd6451aaed0ba9e9baba100",
              "IPY_MODEL_189ae9e176d2490ea7f49c3085eb44ad",
              "IPY_MODEL_bfb3c82d4d9d4504bb24f3da6af2e4d1"
            ],
            "layout": "IPY_MODEL_dc460d3955604711b3660403451ae808"
          }
        },
        "9e87c2d88cd6451aaed0ba9e9baba100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2acf6215b0e47b580876c065069ed5b",
            "placeholder": "​",
            "style": "IPY_MODEL_54284b4d56634d778e44e3be3f76901a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "189ae9e176d2490ea7f49c3085eb44ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0503c4bc477e4b79a653497eb5e8130d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_646e9adbbd7847bbbb411889ff241770",
            "value": 2
          }
        },
        "bfb3c82d4d9d4504bb24f3da6af2e4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44943d1f170241dcbc2d1d2737c12df1",
            "placeholder": "​",
            "style": "IPY_MODEL_96b5addc96cc4da38794f9f685897fe9",
            "value": " 2/2 [00:31&lt;00:00, 14.94s/it]"
          }
        },
        "dc460d3955604711b3660403451ae808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2acf6215b0e47b580876c065069ed5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54284b4d56634d778e44e3be3f76901a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0503c4bc477e4b79a653497eb5e8130d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646e9adbbd7847bbbb411889ff241770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44943d1f170241dcbc2d1d2737c12df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b5addc96cc4da38794f9f685897fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bcd2bea857146f29c18a48fb371fdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df4b587f61a741b582aadc6aefafe4b9",
              "IPY_MODEL_1b177f5559814bd78bb567a717608ca5",
              "IPY_MODEL_1fc453232e7946eb9ad5c741ebf57960"
            ],
            "layout": "IPY_MODEL_bef3a9a8a64b46198c634fe1f238cb31"
          }
        },
        "df4b587f61a741b582aadc6aefafe4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16eb24bb2e841f7b38a45a713cbaa3b",
            "placeholder": "​",
            "style": "IPY_MODEL_cf883133220049bcb946d6cdfbbfe1f3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1b177f5559814bd78bb567a717608ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03acd74f08814aac87d1ecfd819c9c4f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b068dd8de2f438cb043dbcba8f65320",
            "value": 2
          }
        },
        "1fc453232e7946eb9ad5c741ebf57960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7e6fcb4fce4485b1cea34107117907",
            "placeholder": "​",
            "style": "IPY_MODEL_ca96db511ad54870b64f15b4c0b35034",
            "value": " 2/2 [00:38&lt;00:00, 18.67s/it]"
          }
        },
        "bef3a9a8a64b46198c634fe1f238cb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16eb24bb2e841f7b38a45a713cbaa3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf883133220049bcb946d6cdfbbfe1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03acd74f08814aac87d1ecfd819c9c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b068dd8de2f438cb043dbcba8f65320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7e6fcb4fce4485b1cea34107117907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca96db511ad54870b64f15b4c0b35034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rWK_sTEC-ZZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2b5c99-1107-45c1-b87a-df72d4a4faca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install autoawq"
      ],
      "metadata": {
        "id": "-frTbvrlVk-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9703b5f-ca15-4761-d722-543090cd8452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autoawq\n",
            "  Downloading autoawq-0.2.5-cp310-cp310-manylinux2014_x86_64.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m799.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.41.2)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.12.1)\n",
            "Collecting accelerate (from autoawq)\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from autoawq)\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard (from autoawq)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autoawq-kernels (from autoawq)\n",
            "  Downloading autoawq_kernels-0.0.6-cp310-cp310-manylinux2014_x86_64.whl (33.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.12.1->autoawq) (0.23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.1->autoawq)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->autoawq)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->autoawq) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->autoawq)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (2.0.3)\n",
            "Collecting requests (from transformers>=4.35.0->autoawq)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->autoawq)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->autoawq)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->autoawq) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->autoawq) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->autoawq) (1.16.0)\n",
            "Installing collected packages: zstandard, xxhash, requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, autoawq-kernels, accelerate, autoawq\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 autoawq-0.2.5 autoawq-kernels-0.0.6 datasets-2.19.2 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 requests-2.32.3 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/casper-hansen/AutoAWQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstZL_oBV4O9",
        "outputId": "fd4fed21-6c28-42f5-d0bd-e58cfcd96042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AutoAWQ'...\n",
            "remote: Enumerating objects: 3133, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 3133 (delta 7), reused 10 (delta 1), pack-reused 3109\u001b[K\n",
            "Receiving objects: 100% (3133/3133), 7.53 MiB | 14.14 MiB/s, done.\n",
            "Resolving deltas: 100% (1944/1944), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd AutoAWQ"
      ],
      "metadata": {
        "id": "tRWnDPciujwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctransformers"
      ],
      "metadata": {
        "id": "xO6lL3oFV9aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a684b42-f527-4d2d-82c6-73efbcc1d723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.23.2)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2024.2.2)\n",
            "Installing collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svW7LAN-Wz5b",
        "outputId": "315fcfd1-b37c-43ff-e401-bbe46e9f220b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Using cached accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers from source - only needed for versions <= v4.34\n",
        "# pip install git+https://github.com/huggingface/transformers.git\n",
        "# pip install accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-beta\", torch_dtype=torch.bfloat16, device=0)\n",
        "\n",
        "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "  generate me 5 causal examples within those domains{'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'}\"\"\"},\n",
        "]\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])\n",
        "# <|system|>\n",
        "# You are a friendly chatbot who always responds in the style of a pirate.</s>\n",
        "# <|user|>\n",
        "# How many helicopters can a human eat in one sitting?</s>\n",
        "# <|assistant|>\n",
        "# Ah, me hearty matey! But yer question be a puzzler! A human cannot eat a helicopter in one sitting, as helicopters are not edible. They be made of metal, plastic, and other materials, not food!\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c211f0507ef44093ad75aec6ab9ebef8",
            "aaa019be5a374e0387fcc5674f3481e5",
            "4728d058bc8d43b9afae05fb043ef8b0",
            "6bb986b13f6b4b04a673a50875fea56e",
            "1a66927ff51a455da1b10daa48262f1e",
            "ff5a186e393743d296a89e6ebfc2c842",
            "aca9ed7124c345c7a79d967991fb827e",
            "d69c2a2d406d44559bcc7f8209f7ee08",
            "da6ace86c2b04ea1b051720ad785fd05",
            "2c3326ff441348bbbaae6aa2c953261e",
            "ced3ea08f5be4c4ea830a50de8a3dc85"
          ]
        },
        "id": "pqtzCp3nWr_6",
        "outputId": "54944e1e-c699-4ced-bbb8-cde1dc62dd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c211f0507ef44093ad75aec6ab9ebef8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vD33IIlwBPi",
        "outputId": "f1b0f10f-55c0-4349-ad5b-4610abeb8d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.3.0+cu121)\n",
            "Collecting einops (from flash-attn)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=120889689 sha256=5022ba11d48bf74926da9c16260f4ea2b9bb7f4e29bdb4bd6e1383ad1c55d16f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: einops, flash-attn\n",
            "Successfully installed einops-0.8.0 flash-attn-2.5.9.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9deA6yUxplq",
        "outputId": "54398ce9-cdc7-410e-988c-103b86c366ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR5sdc1jd-Wd",
        "outputId": "638ae3ef-0c73-4826-e6e5-8061c3994f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.31.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "  generate me 5 causal examples within those domains{'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'}\n",
        "  <image>Analyze this image and give me a caption.</image>\"\"\"\n",
        "    },\n",
        "]\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "\n",
        "output = pipe(messages, **generation_args)\n",
        "print(output[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954,
          "referenced_widgets": [
            "be7f287381714318aaeb86656a2436ee",
            "9e87c2d88cd6451aaed0ba9e9baba100",
            "189ae9e176d2490ea7f49c3085eb44ad",
            "bfb3c82d4d9d4504bb24f3da6af2e4d1",
            "dc460d3955604711b3660403451ae808",
            "b2acf6215b0e47b580876c065069ed5b",
            "54284b4d56634d778e44e3be3f76901a",
            "0503c4bc477e4b79a653497eb5e8130d",
            "646e9adbbd7847bbbb411889ff241770",
            "44943d1f170241dcbc2d1d2737c12df1",
            "96b5addc96cc4da38794f9f685897fe9"
          ]
        },
        "id": "jzw6_LIPXx41",
        "outputId": "f6819aaa-4721-4f3b-8501-f80c599d24b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be7f287381714318aaeb86656a2436ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1. Economic Events:\n",
            "   <Cause>The increase in interest rates by the central bank</Cause>\n",
            "   <Signal>leads to</Signal>\n",
            "   <Effect>a decrease in consumer spending and a slowdown in economic growth</Effect>\n",
            "\n",
            "   <Cause>A sudden surge in the demand for electric vehicles</Cause>\n",
            "   <Signal>results in</Signal>\n",
            "   <Effect>a significant increase in investments in renewable energy and battery production</Effect>\n",
            "\n",
            "   <Cause>The imposition of heavy tariffs on imported goods</Cause>\n",
            "   <Signal>causes</Signal>\n",
            "   <Effect>a trade war between countries, affecting global supply chains</Effect>\n",
            "\n",
            "   <Cause>A major technological breakthrough in agricultural productivity</Cause>\n",
            "   <Signal>brings about</Signal>\n",
            "   <Effect>a decrease in food prices and an improvement in global food security</Effect>\n",
            "\n",
            "   <Cause>The collapse of a major financial institution</Cause>\n",
            "   <Signal>triggers</Signal>\n",
            "   <Effect>a global financial crisis, with widespread economic repercussions</Effect>\n",
            "\n",
            "2. Social Events:\n",
            "   <Cause>The rise of social media platforms</Cause>\n",
            "   <Signal>has led to</Signal>\n",
            "   <Effect>increased awareness and mobilization for social justice issues</Effect>\n",
            "\n",
            "   <Cause>The implementation of comprehensive education reforms</Cause>\n",
            "   <Signal>results in</Signal>\n",
            "   <Effect>improved literacy rates and higher educational attainment</Effect>\n",
            "\n",
            "   <Cause>The spread of a viral health campaign</Cause>\n",
            "   <Signal>causes</Signal>\n",
            "   <Effect>a significant reduction in the prevalence of a particular disease</Effect>\n",
            "\n",
            "   <Cause>The introduction of a new cultural festival</Cause>\n",
            "   <Signal>brings about</Signal>\n",
            "   <Effect>a boost in tourism and local economic development</Effect>\n",
            "\n",
            "   <Cause>The enforcement of stricter gun control laws\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "\n",
        "# Load the model and processor\n",
        "model_id = \"microsoft/Phi-3-vision-128k-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype=\"auto\", _attn_implementation='flash_attention_2')\n",
        "model.to(\"cuda\")  # Move the model to GPU\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# Define the image and prompt\n",
        "#url = \"https://assets-c4akfrf5b4d3f4b7.z01.azurefd.net/assets/2024/04/BMDataViz_661fb89f3845e.png\"\n",
        "#image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "  generate me 5 causal examples within those domains{'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'}\n",
        "  <image>Analyze this image and give me a caption.</image>\"\"\" # Added image tag\n",
        "    }\n",
        "]\n",
        "\n",
        "# Apply chat template to the messages\n",
        "prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "# Generate text based on the input\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "\n",
        "generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
        "\n",
        "# Remove input tokens\n",
        "generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
        "response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "GKzhY8uW9Eoh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "9bcd2bea857146f29c18a48fb371fdd2",
            "df4b587f61a741b582aadc6aefafe4b9",
            "1b177f5559814bd78bb567a717608ca5",
            "1fc453232e7946eb9ad5c741ebf57960",
            "bef3a9a8a64b46198c634fe1f238cb31",
            "c16eb24bb2e841f7b38a45a713cbaa3b",
            "cf883133220049bcb946d6cdfbbfe1f3",
            "03acd74f08814aac87d1ecfd819c9c4f",
            "1b068dd8de2f438cb043dbcba8f65320",
            "7f7e6fcb4fce4485b1cea34107117907",
            "ca96db511ad54870b64f15b4c0b35034"
          ]
        },
        "outputId": "538817ed-52c8-4348-87b0-2f9bd213f4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bcd2bea857146f29c18a48fb371fdd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6d3b102952dc>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"microsoft/Phi-3-vision-128k-instruct\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attn_implementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flash_attention_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Move the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m                 )\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     )\n\u001b[0;32m-> 1159\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set the environment variable to specify which GPU to use\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Change \"0\" to any other GPU index if needed\n",
        "\n",
        "# Check if GPU is available\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"CUDA is not available. Please check your GPU setup.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Optional: set environment variable for memory management\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "# Load the model with reduced precision and gradient checkpointing\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model with gradient checkpointing and low precision\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    gradient_checkpointing=True\n",
        ").to(device)\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator(fp16=True)\n",
        "model = model.to(accelerator.device)\n",
        "tokenizer = tokenizer.to(accelerator.device)\n",
        "\n",
        "\n",
        "# Define the pipeline manually to use the model and tokenizer\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "  generate me 5 causal examples within those domains{'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'}\"\"\"},\n",
        "]\n",
        "\n",
        "# Apply chat template and generate text\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "\n",
        "# Print the generated text\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "CbXUO4QCMDB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Set the environment variable to specify which GPU to use\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Change \"0\" to any other GPU index if needed\n",
        "\n",
        "# Check if GPU is available\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"CUDA is not available. Please check your GPU setup.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Optional: set environment variable for memory management\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
        "\n",
        "# Load the model with reduced precision\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load model with low precision\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        ").to(device)\n",
        "\n",
        "# Define the pipeline manually to use the model and tokenizer\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "  generate me 5 causal examples within those domains{'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'}\"\"\"},\n",
        "]\n",
        "\n",
        "# Apply chat template and generate text\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "\n",
        "# Print the generated text\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "OMF0dhG6Nox9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "domains=[ 'economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events'\n",
        "\n",
        "]\n",
        "request = \"\"\"\n",
        "generate me 5 causal examples\n",
        "\"\"\"\n",
        "\n",
        "definition=\"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "\n",
        "  Please generate causal sentences within this domains.\"\"\"\n",
        "\n",
        "for d in domains:\n",
        "\n",
        "\n",
        "  prompt_template=f'''<|system|>\n",
        "  </s>\n",
        "  <|user|>\n",
        "  {request + 'in the omain of ' +\n",
        "    str(d) + definition }</s>\n",
        "  <|assistant|>\n",
        "  '''\n",
        "\n",
        "  print(\"*** Running model.generate:\")\n",
        "\n",
        "  token_input = tokenizer(\n",
        "      prompt_template,\n",
        "      return_tensors='pt'\n",
        "  ).input_ids.cuda()\n",
        "  # Open a file named 'domain.txt' in write mode\n",
        "  with open('domain.txt', 'w') as file:\n",
        "  # Write the content of the string to the file\n",
        "    file.write(prompt_template)\n",
        "\n",
        "  # Generate output\n",
        "  generation_output = model.generate(\n",
        "      token_input,\n",
        "      do_sample=True,\n",
        "      temperature=0.7,\n",
        "      top_p=0.95,\n",
        "      top_k=40,\n",
        "      max_new_tokens=512\n",
        "  )\n",
        "\n",
        "  # Get the tokens from the output, decode them, print them\n",
        "  token_output = generation_output[0]\n",
        "  text_output = tokenizer.decode(token_output)\n",
        "  print(\"LLM output: \", text_output)\n",
        "\n",
        "\"\"\"\n",
        "# Inference should be possible with transformers pipeline as well in future\n",
        "# But currently this is not yet supported by AutoAWQ (correct as of September 25th 2023)\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"*** Pipeline:\")\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    top_k=40,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "IOgxYbXfWl9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "71d8da26-0ad7-4b5e-bc7a-b6cf2fdbb333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RepositoryNotFoundError",
          "evalue": "401 Client Error. (Request ID: Root=1-6660587a-5783aeef7eee5d1c6037c06e;bffa40da-6d33-4e1f-a24a-f6bcaa567b41)\n\nRepository Not Found for url: https://huggingface.co/api/models/zephyr-7b-alpha.Q4_K_M.gguf?blobs=True.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/zephyr-7b-alpha.Q4_K_M.gguf?blobs=True",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c6f426dd8f34>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m conf = AutoConfig(Config(temperature=0.7, repetition_penalty=1.1, batch_size=52,\n\u001b[1;32m      3\u001b[0m              max_new_tokens=1024, context_length=2048))\n\u001b[0;32m----> 4\u001b[0;31m llm = AutoModelForCausalLM.from_pretrained('zephyr-7b-alpha.Q4_K_M.gguf',\n\u001b[0m\u001b[1;32m      5\u001b[0m                       model_type='mistral', config=conf)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/hub.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             )\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"repo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             model_path = cls._find_model_path_from_repo(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mmodel_path_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/hub.py\u001b[0m in \u001b[0;36m_find_model_path_from_repo\u001b[0;34m(cls, repo_id, filename, local_files_only, revision)\u001b[0m\n\u001b[1;32m    196\u001b[0m     ) -> str:\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             filename = cls._find_model_file_from_repo(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/hub.py\u001b[0m in \u001b[0;36m_find_model_file_from_repo\u001b[0;34m(cls, repo_id, revision)\u001b[0m\n\u001b[1;32m    216\u001b[0m     ) -> Optional[str]:\n\u001b[1;32m    217\u001b[0m         \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         repo_info = api.repo_info(\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mfiles_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mrepo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   2489\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported repo type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m         return method(\n\u001b[0m\u001b[1;32m   2492\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   2299\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"blobs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2301\u001b[0;31m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2302\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;34m\" make sure you are authenticated.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6660587a-5783aeef7eee5d1c6037c06e;bffa40da-6d33-4e1f-a24a-f6bcaa567b41)\n\nRepository Not Found for url: https://huggingface.co/api/models/zephyr-7b-alpha.Q4_K_M.gguf?blobs=True.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from awq import AutoAWQForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name_or_path = \"TheBloke/zephyr-7B-beta-AWQ\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
        "# Load model\n",
        "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,\n",
        "                                          trust_remote_code=False, safetensors=True)\n",
        "\n",
        "domains = ['economic events', 'social events', 'political unrest', 'elections', 'natural disasters', 'transport accidents', 'crimes', 'industrial accidents', 'international relations', 'home policy', 'MUC-like events', 'KBP-like events']\n",
        "\n",
        "request = \"\"\"\n",
        "generate me 5 causal examples for each domain in domains\n",
        "\"\"\"\n",
        "\n",
        "definition = \"\"\"Below are the definitions for the tags in the sentence:\n",
        "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
        "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
        "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
        "\n",
        "  Please generate causal sentences within this domains.\"\"\"\n",
        "\n",
        "# Open a file named 'domain.txt' in write mode\n",
        "with open('domain.txt', 'w') as file:\n",
        "    for d in domains:\n",
        "        prompt_template = f'''\n",
        "        </s>\n",
        "\n",
        "        {request + 'in the domain of ' +\n",
        "            str(d) + definition}</s>\n",
        "\n",
        "        '''\n",
        "\n",
        "        print(\"*** Running model.generate:\")\n",
        "\n",
        "        token_input = tokenizer(\n",
        "            prompt_template,\n",
        "            return_tensors='pt'\n",
        "        ).input_ids.cuda()\n",
        "\n",
        "        # Generate output\n",
        "        generation_output = model.generate(\n",
        "            token_input,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            top_k=40,\n",
        "            max_new_tokens=512\n",
        "        )\n",
        "\n",
        "        # Get the tokens from the output, decode them, print them\n",
        "        token_output = generation_output[0]\n",
        "        text_output = tokenizer.decode(token_output)\n",
        "        print(\"LLM output: \", text_output)\n",
        "\n",
        "        # Write the generated text to the file\n",
        "        file.write(text_output + '\\n')"
      ],
      "metadata": {
        "id": "IsfbRoRZDL9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3525eda754364f6986d84f9b5c149b98",
            "08c4581588a34aaca89a8ed5d8e333e5",
            "bec973caa7e24090a4fe75f569835c56",
            "3c2f8556fab9447e8a6745e878ca9511",
            "be3ce4a27dc24d9a9282696ba2b02826",
            "ad425b2d5e684deaa54dee0d6cf975a5",
            "d3da4f087b7846f1bf04ab515c1e1d80",
            "8350ae4e0a134cbc8685d64036ac2a53",
            "301f296826fd4d549964a00567c4d472",
            "c76de96db57a4e548880154c0d3d4448",
            "e74d53665bc748f4bb731f120bdf69d1"
          ]
        },
        "outputId": "a872d7fa-6a34-42c4-c41f-4d610148a7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3525eda754364f6986d84f9b5c149b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Replacing layers...: 100%|██████████| 32/32 [00:09<00:00,  3.42it/s]\n",
            "Fusing layers...: 100%|██████████| 32/32 [00:00<00:00, 53.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of economic eventsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<!user!>\n",
            "Can you please provide me with 5 causal examples for each domain in domains? I need them for a report I'm working on. The domains I need examples for are: economic events, natural disasters, medical conditions, and technological advancements. Please use the definitions provided in the text for the tags in the sentences. I appreciate your help!</s>\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of social eventsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> A lack of RSVPs from potential attendees.\n",
            "<SIG0> May result in.\n",
            "<ARG1> Low attendance at a social event.\n",
            "\n",
            "Example: A lack of RSVPs from potential attendees may result in low attendance at the social event.\n",
            "\n",
            "<ARG0> Poor communication between the event organizer and guests.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Confusion about the event details and location.\n",
            "\n",
            "Example: Poor communication between the event organizer and guests leads to confusion about the event details and location.\n",
            "\n",
            "<ARG0> Inadequate promotion of the event through social media and other channels.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Low awareness about the event among the target audience.\n",
            "\n",
            "Example: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\n",
            "\n",
            "<ARG0> Last-minute cancellations by key speakers or performers.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Changes in the event program and schedule.\n",
            "\n",
            "Example: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\n",
            "\n",
            "<ARG0> Poor planning and organization by the event team.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Chaos and disorganization at the event venue.\n",
            "\n",
            "Example: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\n",
            "\n",
            "In the domain of technology:\n",
            "\n",
            "<ARG0> A malfunctioning computer system.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Downtime and reduced productivity.\n",
            "\n",
            "Example: A malfunctioning computer system causes downtime and reduced productivity.\n",
            "\n",
            "<ARG0> Outdated software and hardware.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Sluggish performance and increased maintenance costs.\n",
            "\n",
            "Example: Outdated software and hardware results in sluggish performance and increased maintenance costs.\n",
            "\n",
            "<ARG0> Inadequate cybersecurity measures.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Data breaches and loss of sensitive information.\n",
            "\n",
            "Example: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\n",
            "\n",
            "<ARG0> Insufficient training for employees on new technology.\n",
            "<SIG0>\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of political unrestBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<Domain: Domestic Politics>\n",
            "\n",
            "1. Cause: Increased income inequality.\n",
            "   Effect: Rise in political unrest.\n",
            "   Signal: As income inequality continues to grow, it has led to an increase in political unrest as people become more dissatisfied with the status quo and demand change.\n",
            "\n",
            "2. Cause: Corruption scandals.\n",
            "   Effect: Loss of public trust in government.\n",
            "   Signal: The recent wave of corruption scandals has eroded public trust in government, leading to increased political unrest as people demand accountability and reform.\n",
            "\n",
            "3. Cause: Economic downturns.\n",
            "   Effect: Increased political unrest.\n",
            "   Signal: During times of economic hardship, people are more likely to take to the streets to demand change and protest against the government's handling of the situation.\n",
            "\n",
            "4. Cause: Lack of representation in government.\n",
            "   Effect: Political unrest.\n",
            "   Signal: When people feel that their voices are not being heard in government, they are more likely to take to the streets to demand change and call for greater representation.\n",
            "\n",
            "5. Cause: Political polarization.\n",
            "   Effect: Increased political unrest.\n",
            "   Signal: As political parties become increasingly polarized, it can lead to increased political unrest as people become more entrenched in their ideological positions and less willing to compromise.\n",
            "\n",
            "<Domain: International Relations>\n",
            "\n",
            "1. Cause: Violation of international law.\n",
            "   Effect: Diplomatic tensions.\n",
            "   Signal: When a country violates international law, it can lead to diplomatic tensions as other countries respond with sanctions, protests, or other forms of pressure.\n",
            "\n",
            "2. Cause: Armed conflict.\n",
            "   Effect: Political instability.\n",
            "   Signal: Armed conflict can lead to political instability as civilians become displaced, infrastructure is destroyed, and governance becomes more difficult.\n",
            "\n",
            "3. Cause: Human rights abuses.\n",
            "   Effect: International condemnation.\n",
            "   Signal: When a country engages in human rights abuses, it can lead to international condemnation, as other countries and international organizations speak out against the abuse and demand accountability.\n",
            "\n",
            "4. Cause: Economic sanctions.\n",
            "   Effect: Political unrest.\n",
            "   Signal: Economic san\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of electionsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> A high voter turnout leads to a lower chance of election fraud.\n",
            "<SIG0> As a result, the integrity of the electoral process is upheld.\n",
            "<ARG1> This is because a large number of people present at polling stations makes it harder for fraudsters to manipulate the results.\n",
            "\n",
            "<ARG0> A lack of transparency in the election process can result in a loss of public trust.\n",
            "<SIG0> Therefore, it is crucial for electoral bodies to ensure that all aspects of the election are conducted in a fair and transparent manner.\n",
            "<ARG1> This includes providing access to detailed election data and allowing independent observers to monitor the process.\n",
            "\n",
            "<ARG0> The use of electronic voting machines can increase efficiency and reduce the likelihood of human error.\n",
            "<SIG0> However, it is essential to ensure that these machines are secure and accurate, and that they are subjected to rigorous testing and auditing.\n",
            "<ARG1> This includes regular maintenance and software updates, as well as the use of paper ballots as a backup in case of machine failure.\n",
            "\n",
            "<ARG0> A lack of campaign finance regulation can result in unfair advantages for wealthy candidates.\n",
            "<SIG0> Therefore, it is necessary to implement strict campaign finance laws that limit the amount of money that can be spent on campaigns and require disclosure of all donations.\n",
            "<ARG1> This helps to level the playing field and ensures that candidates are chosen based on their policies and qualifications, rather than their wealth.\n",
            "\n",
            "<ARG0> The presence of third-party candidates in an election can split the vote and lead to the election of a less popular candidate.\n",
            "<SIG0> Therefore, it is crucial to ensure that third-party candidates are given a fair chance to participate in debates and have their platforms heard.\n",
            "<ARG1> This can include providing equal airtime and resources to all candidates, and avoiding overt partisanship in the media coverage of the election.\n",
            "\n",
            "<ARG0> The use of gerrymandering can result in an unfair advantage for one political party over another.\n",
            "<SIG0> Therefore, it is necessary to ensure that district boundaries are drawn in a fair and impartial manner, and that they accurately reflect the population of the area.\n",
            "<ARG1> This can include the use of independent commissions to oversee the redistricting process, and the implementation of\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of natural disastersBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> The earthquake struck suddenly,\n",
            "<SIG0> causing,\n",
            "<ARG1> destructive tremors,\n",
            "</SIG0> in the region.\n",
            "\n",
            "<ARG0> The volcano erupted violently,\n",
            "<SIG0> causing,\n",
            "<ARG1> lava and ash to spew forth,\n",
            "</SIG0> in a spectacular display.\n",
            "\n",
            "<ARG0> The hurricane swept through the area,\n",
            "<SIG0> causing,\n",
            "<ARG1> widespread flooding and destruction,\n",
            "</SIG0> in its path.\n",
            "\n",
            "<ARG0> The tsunami hit without warning,\n",
            "<SIG0> causing,\n",
            "<ARG1> devastating damage to coastal towns,\n",
            "</SIG0> in its wake.\n",
            "\n",
            "<ARG0> The wildfire raged out of control,\n",
            "<SIG0> causing,\n",
            "<ARG1> massive destruction of forests and homes,\n",
            "</SIG0> in its path.\n",
            "\n",
            "\n",
            "\n",
            "<ARG0> The drought persisted for months on end,\n",
            "<SIG0> causing,\n",
            "<ARG1> crops to wither and die,\n",
            "</SIG0> in the parched fields.\n",
            "\n",
            "<ARG0> The hurricane hit with unprecedented force,\n",
            "<SIG0> causing,\n",
            "<ARG1> massive destruction of buildings and infrastructure,\n",
            "</SIG0> in its path.\n",
            "\n",
            "<ARG0> The tsunami struck without warning,\n",
            "<SIG0> causing,\n",
            "<ARG1> thousands of deaths and widespread destruction,\n",
            "</SIG0> in its wake.\n",
            "\n",
            "<ARG0> The wildfire tore through the forest,\n",
            "<SIG0> causing,\n",
            "<ARG1> the displacement of hundreds of families and the destruction of homes,\n",
            "</SIG0> in its path.\n",
            "\n",
            "<ARG0> The drought persisted for years,\n",
            "<SIG0> causing,\n",
            "<ARG1> a severe shortage of water and food,\n",
            "</SIG0> in the affected regions.\n",
            "\n",
            "\n",
            "\n",
            "<ARG0> The earthquake struck suddenly,\n",
            "<SIG0> triggering,\n",
            "<ARG1> a series of aftershocks that continued for days,\n",
            "</SIG0> in the region.\n",
            "\n",
            "<ARG0> The hurricane hit with unprecedented force,\n",
            "<SIG0> unleashing,\n",
            "<\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of transport accidentsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> A drunk driver gets behind the wheel of a car.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A car accident occurs.\n",
            "\n",
            "<ARG0> A driver fails to yield to a pedestrian in a crosswalk.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A pedestrian accident occurs.\n",
            "\n",
            "<ARG0> A driver disregards a red light at an intersection.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A multi-car accident occurs.\n",
            "\n",
            "<ARG0> A driver operates a vehicle at an excessive speed.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The driver loses control of the vehicle and causes a rollover accident.\n",
            "\n",
            "<ARG0> A driver becomes distracted by a cellphone while driving.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A rear-end collision occurs.\n",
            "\n",
            "<ARG0> A driver falls asleep at the wheel due to fatigue.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A serious car accident occurs.\n",
            "\n",
            "<ARG0> A driver neglects to properly secure a load on a truck.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A load falls off the truck and causes a road hazard, potentially leading to an accident.\n",
            "\n",
            "<ARG0> A driver fails to properly adjust their vehicle's mirrors, causing blind spots.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A sideswipe accident occurs.\n",
            "\n",
            "<ARG0> A driver operates a vehicle with faulty brakes.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A rear-end collision occurs due to the driver's inability to stop in time.\n",
            "\n",
            "<ARG0> A driver fails to properly maintain their vehicle, leading to mechanical failures.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> An unexpected breakdown occurs, potentially leading to an accident.\n",
            "\n",
            "<ARG0> A driver engages in aggressive driving behaviors, such as tailgating and weaving in and out of traffic.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> Road rage incidents and accidents resulting from these behaviors occur.\n",
            "\n",
            "<ARG0> A driver becomes disoriented due to a medical condition, such as a seizure or stroke.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> A serious car accident occurs.\n",
            "\n",
            "<ARG0> A driver is imp\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of crimesBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<Domain: Crimes>\n",
            "\n",
            "1) Cause: The thief saw an opportunity to break into the house.\n",
            "   Effect: The thief stole the expensive watch.\n",
            "   Signal: So,\n",
            "\n",
            "   Example: The thief, who saw an opportunity to break into the house, stole the expensive watch, so.</SIG0>\n",
            "\n",
            "2) Cause: The criminal's desperation for money made him commit the robbery.\n",
            "   Effect: The criminal stole the jewelry store.\n",
            "   Signal: Therefore,\n",
            "\n",
            "   Example: The criminal, who was desperate for money, stole the jewelry store, therefore.</SIG0>\n",
            "\n",
            "3) Cause: The terrorist's belief in the cause led him to carry out the bombing.\n",
            "   Effect: The city was in chaos after the bombing.\n",
            "   Signal: Hence,\n",
            "\n",
            "   Example: The terrorist, who believed in the cause, carried out the bombing, hence</SIG0>\n",
            "\n",
            "4) Cause: The gang's anger towards the victim led to the brutal assault.\n",
            "   Effect: The victim was left with serious injuries.\n",
            "   Signal: Consequently,\n",
            "\n",
            "   Example: The gang, who were angry towards the victim, carried out a brutal assault, consequently</SIG0>\n",
            "\n",
            "5) Cause: The criminal's need for drugs led to the burglary.\n",
            "   Effect: The store was robbed of expensive merchandise.\n",
            "   Signal: As a result,\n",
            "\n",
            "   Example: The criminal, who needed drugs, carried out the burglary, as a result</SIG0>\n",
            "\n",
            "<|user|>\n",
            "These examples are great! Can you provide some more examples for the domain of accidents? And maybe explain how to identify the cause and effect in a real-life accident?</s>\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of industrial accidentsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> The use of outdated equipment.\n",
            "<SIG0> Led to.\n",
            "<ARG1> Equipment failure during the manufacturing process.\n",
            "\n",
            "<ARG0> Improper storage of hazardous materials.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Leakage and release of hazardous substances into the environment.\n",
            "\n",
            "<ARG0> Inadequate training of employees.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Safety violations and accidents in the workplace.\n",
            "\n",
            "<ARG0> Neglect of regular maintenance.\n",
            "<SIG0> Caused.\n",
            "<ARG1> Malfunctioning of machinery and equipment.\n",
            "\n",
            "<ARG0> Lack of proper safety protocols.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Injuries and fatalities among workers and the community.\n",
            "\n",
            "\n",
            "\n",
            "<ARG0> Inadequate risk assessment.\n",
            "<SIG0> Led to.\n",
            "<ARG1> Failure to anticipate and mitigate potential hazards.\n",
            "\n",
            "<ARG0> Insufficient emergency response planning.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Inadequate response to accidents and disasters.\n",
            "\n",
            "<ARG0> Lack of communication and coordination among workers and emergency responders.\n",
            "<SIG0> Led to.\n",
            "<ARG1> Confusion and delays in responding to accidents and emergencies.\n",
            "\n",
            "<ARG0> Failure to prioritize safety in decision-making.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Financial losses, legal liabilities, and damage to the company's reputation.\n",
            "\n",
            "<ARG0> Ignoring safety recommendations and warnings.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Repeated incidents of accidents and injuries.\n",
            "\n",
            "<ARG0> Inadequate attention to safety in the design and planning phases.\n",
            "<SIG0> Led to.\n",
            "<ARG1> Defective and hazardous products and facilities.\n",
            "\n",
            "<ARG0> Failure to properly manage and monitor safety performance.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> Persistent safety issues and accidents.\n",
            "\n",
            "<ARG0> Neglecting to conduct regular safety audits and inspections.\n",
            "<SIG0> Led to.\n",
            "<ARG1> Undetected safety hazards and failures\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of international relationsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0> A territorial dispute between two neighboring countries over a border region.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Diplomatic tensions, military build-ups, and occasional armed clashes.\n",
            "\n",
            "<ARG0> A lack of economic opportunities and social mobility in a region.\n",
            "<SIG0> Results in.\n",
            "<ARG1> High levels of poverty, inequality, and political instability.\n",
            "\n",
            "<ARG0> The spread of a contagious disease in a population.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Outbreaks, epidemics, and a significant burden on the healthcare system.\n",
            "\n",
            "<ARG0> A cyber attack on a critical infrastructure system, such as a power grid or a transportation network.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Disruption of services, potential for physical harm to people, and economic losses.\n",
            "\n",
            "<ARG0> A shortage of fresh water resources due to drought or overuse.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Water scarcity, conflicts over shared water resources, and environmental degradation.</s>\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of home policyBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<Domain>\n",
            "Home Policy\n",
            "\n",
            "Cause: The local government has implemented a new tax policy.\n",
            "Effect: The residents have to pay more for property tax.\n",
            "Signal: As a result of.\n",
            "\n",
            "Cause: The local government has increased the budget for public works.\n",
            "Effect: The streets are now in better condition.\n",
            "Signal: Therefore.\n",
            "\n",
            "Cause: The local government has passed a new zoning law.\n",
            "Effect: The construction of new buildings is now subject to stricter guidelines.\n",
            "Signal: Consequently.\n",
            "\n",
            "Cause: The local government has allocated more funds for emergency services.\n",
            "Effect: The response time for emergency calls has decreased.\n",
            "Signal: Therefore.\n",
            "\n",
            "Cause: The local government has introduced a new recycling program.\n",
            "Effect: The environment has become cleaner and healthier.\n",
            "Signal: As a result of.\n",
            "\n",
            "<Domain>\n",
            "Education\n",
            "\n",
            "Cause: The school district has implemented a new curriculum.\n",
            "Effect: The students are now learning more advanced concepts.\n",
            "Signal: As a result of.\n",
            "\n",
            "Cause: The school district has hired more teachers.\n",
            "Effect: The class sizes have decreased.\n",
            "Signal: Therefore.\n",
            "\n",
            "Cause: The school district has provided more resources for after-school programs.\n",
            "Effect: The students are now more engaged in extracurricular activities.\n",
            "Signal: Consequently.\n",
            "\n",
            "Cause: The school district has increased the salaries of teachers.\n",
            "Effect: The school district is now able to attract and retain more qualified teachers.\n",
            "Signal: Therefore.\n",
            "\n",
            "Cause: The school district has introduced a new standardized testing system.\n",
            "Effect: The students are now better prepared for college-level coursework.\n",
            "Signal: As a result of.\n",
            "\n",
            "<Domain>\n",
            "Healthcare\n",
            "\n",
            "Cause: The healthcare system has implemented a new electronic medical records system.\n",
            "Effect: Patient information is now more easily accessible to healthcare providers.\n",
            "Signal: As a result of.\n",
            "\n",
            "Cause: The healthcare system has increased funding for medical research.\n",
            "Effect: New treatments and cures for diseases are now being developed.\n",
            "Signal: Therefore.\n",
            "\n",
            "Cause: The healthcare system has expanded access to preventative care services.\n",
            "Effect: The overall health of the population has improved.\n",
            "Signal: Consequently.\n",
            "\n",
            "Cause: The healthcare system has introduced a new telemedicine program.\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of MUC-like eventsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<ARG0>A bacterial infection causes fever and chills.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The patient's body temperature rises and the person experiences shivering.\n",
            "\n",
            "<ARG0>An allergy causes itchiness and swelling.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The affected area becomes red and inflamed.\n",
            "\n",
            "<ARG0>Smoking causes lung cancer.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The development of malignant cells in the lungs.\n",
            "\n",
            "<ARG0>Exposure to sunlight causes sunburn.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The skin becomes tender, red, and peels.\n",
            "\n",
            "<ARG0>Eating contaminated food causes food poisoning.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The individual experiences nausea, vomiting, and diarrhea.\n",
            "\n",
            "<ARG0>Working in a noisy environment causes hearing loss.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The person's ability to hear becomes impaired.\n",
            "\n",
            "<ARG0>Drinking too much alcohol causes intoxication.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The individual's behavior and judgment become impaired.\n",
            "\n",
            "<ARG0>Lack of sleep causes fatigue.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The individual feels tired and lacks energy.\n",
            "\n",
            "<ARG0>Eating a lot causes weight gain.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The person's body mass index increases.\n",
            "\n",
            "<ARG0>Exercising regularly causes muscle growth.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The individual's muscles become larger and more defined.\n",
            "\n",
            "<ARG0>Inhaling secondhand smoke causes respiratory problems.\n",
            "<SIG0>This leads to.\n",
            "<ARG1>The individual experiences coughing, wheezing, and shortness of breath.\n",
            "\n",
            "<ARG0>Using a tanning bed causes skin cancer.\n",
            "<SIG0>This results in.\n",
            "<ARG1>The development of malignant cells in the skin.\n",
            "\n",
            "<ARG0>Consuming too much sugar causes tooth decay.\n",
            "<SIG0>\n",
            "*** Running model.generate:\n",
            "LLM output:  <s> \n",
            "        </s> \n",
            "\n",
            "        \n",
            "generate me 5 causal examples for each domain in domains\n",
            "in the domain of KBP-like eventsBelow are the definitions for the tags in the sentence:\n",
            "  Cause: The reason for an event happening, to be enclosed between <ARG0> and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between <SIG0> and </SIG0>.\n",
            "\n",
            "  Please generate causal sentences within this domains.</s> \n",
            "\n",
            "        \n",
            "<Domain: Healthcare>\n",
            "\n",
            "1. Cause: The patient's high blood pressure and diabetes.\n",
            "   Effect: The patient's doctor recommends lifestyle changes and medication.\n",
            "   Signal: \"Based on your medical history, I recommend...\"\n",
            "\n",
            "2. Cause: The patient's persistent cough and fever.\n",
            "   Effect: The patient undergoes chest x-rays and lab tests to diagnose pneumonia.\n",
            "   Signal: \"To determine the cause of your symptoms, we will...\"\n",
            "\n",
            "3. Cause: The patient's recent injury.\n",
            "   Effect: The patient receives emergency medical care and is admitted to the hospital.\n",
            "   Signal: \"After assessing your injuries, we recommend...\"\n",
            "\n",
            "4. Cause: The patient's allergy to medication.\n",
            "   Effect: The patient's doctor prescribes an alternative medication to avoid allergic reactions.\n",
            "   Signal: \"Given your allergy to... We recommend...\"\n",
            "\n",
            "5. Cause: The patient's symptoms of depression and anxiety.\n",
            "   Effect: The patient begins therapy and medication to manage mental health conditions.\n",
            "   Signal: \"After evaluating your symptoms, we suggest...\"\n",
            "\n",
            "<Domain: Education>\n",
            "\n",
            "1. Cause: The student's poor performance on exams.\n",
            "   Effect: The student meets with an academic advisor to develop a study plan.\n",
            "   Signal: \"Based on your exam results, we suggest...\"\n",
            "\n",
            "2. Cause: The student's absence from class due to illness.\n",
            "   Effect: The student works with a tutor to catch up on missed material.\n",
            "   Signal: \"To help you make up for missed class time, we recommend...\"\n",
            "\n",
            "3. Cause: The student's low grade in a specific subject.\n",
            "   Effect: The student attends after-school study sessions with a teacher.\n",
            "   Signal: \"To improve your grade in this subject, we suggest...\"\n",
            "\n",
            "4. Cause: The student's lack of motivation to complete assignments.\n",
            "   Effect: The student meets with a counselor to discuss strategies for improving focus and organization.\n",
            "   Signal: \"To address your lack of motivation, we recommend...\"\n",
            "\n",
            "5. Cause: The student's struggle to understand a particular concept.\n",
            "   Effect: The student attends a study group with classmates to collaboratively\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the txt file, concatenat the examples in a csv fil.\n"
      ],
      "metadata": {
        "id": "KM1fXCETDRPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Function to extract causal relations from a sentence\n",
        "def extract_causal_relations(sentence):\n",
        "    # Placeholder function, you would implement this according to your specific causal relation extraction method\n",
        "    # For demonstration purposes, let's assume no causal relations are extracted\n",
        "    return []\n",
        "\n",
        "# Function to write data to CSV file\n",
        "def write_to_csv(data, output_filename):\n",
        "    with open(output_filename, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text', 'causal_text', 'num_rs']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# Load causal text file\n",
        "with open('/content/generated_examples (2).txt', 'r') as file:\n",
        "    causal_text = file.read()\n",
        "\n",
        "# Tokenize into sentences\n",
        "sentences = sent_tokenize(causal_text)\n",
        "\n",
        "# Initialize data list to hold rows for CSV\n",
        "csv_data = []\n",
        "\n",
        "# Process each sentence\n",
        "for sent_id, sentence in enumerate(sentences, start=1):\n",
        "    causal_relations = extract_causal_relations(sentence)\n",
        "    eg_id = 0\n",
        "    for index, causal_text_w_pairs in enumerate(causal_relations, start=1):\n",
        "        eg_id += 1\n",
        "        num_rs = len(causal_text_w_pairs)\n",
        "        row = {\n",
        "            'corpus': 'Corpus',\n",
        "            'doc_id': 'doc_id',\n",
        "            'sent_id': sent_id,\n",
        "            'eg_id': eg_id,\n",
        "            'index': f'{sent_id}_{eg_id}',\n",
        "            'text': sentence,\n",
        "            'causal_text': causal_text,\n",
        "            'num_rs': num_rs\n",
        "        }\n",
        "        csv_data.append(row)\n",
        "\n",
        "# Write data to CSV file\n",
        "write_to_csv(csv_data, '/content/train_subtask2_grouped.csv')\n",
        "\n",
        "print(\"CSV file saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoKX1THH3kJ1",
        "outputId": "6fec6c62-a0fc-4494-fdde-8ebacbfb28b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Function to extract causal relations from a sentence\n",
        "def extract_causal_relations(sentence):\n",
        "    # Placeholder function, you would implement this according to your specific causal relation extraction method\n",
        "    # For demonstration purposes, let's assume no causal relations are extracted\n",
        "    examples = []\n",
        "    domain_start = 0\n",
        "    text = sentence\n",
        "    while True:\n",
        "        domain_start = text.find(\"<ARG0>\", domain_start)\n",
        "        if domain_start == -1:\n",
        "            break\n",
        "\n",
        "        domain_end = text.find(\"</s>\", domain_start)\n",
        "        domain_text = text[domain_start:domain_end]\n",
        "\n",
        "        cause_start = domain_text.find(\"<ARG0>\") + len(\"<ARG0>\")\n",
        "        cause_end = domain_text.find(\"<SIG0>\")\n",
        "        cause = domain_text[cause_start:cause_end].strip()\n",
        "\n",
        "        signal_start = cause_end + len(\"<SIG0>\")\n",
        "        signal_end = domain_text.find(\"</SIG0>\")\n",
        "        signal = domain_text[signal_start:signal_end].strip()\n",
        "\n",
        "        effect_start = signal_end + len(\"</SIG0>\")\n",
        "        effect_end = domain_text.find(\"</ARG1>\")\n",
        "        effect = domain_text[effect_start:effect_end].strip()\n",
        "\n",
        "        examples.append({\n",
        "            'text': cause + ' ' + signal + ' ' + effect,\n",
        "            'causal_text': [cause, signal, effect],\n",
        "        })\n",
        "\n",
        "        domain_start = domain_end + len(\"</s>\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Function to write data to CSV file\n",
        "def write_to_csv(data, output_filename):\n",
        "    with open(output_filename, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['corpus', 'doc_id', 'sent_id', 'eg_id', 'index', 'text', 'causal_text', 'num_rs']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "# Load causal text file\n",
        "with open('/content/generated_examples (2).txt', 'r') as file:\n",
        "    causal_text = file.read()\n",
        "\n",
        "# Tokenize into sentences\n",
        "sentences = sent_tokenize(causal_text)\n",
        "\n",
        "# Initialize data list to hold rows for CSV\n",
        "csv_data = []\n",
        "\n",
        "# Process each sentence\n",
        "for sent_id, sentence in enumerate(sentences, start=1):\n",
        "    causal_relations = extract_causal_relations(sentence)\n",
        "    eg_id = 0\n",
        "    for index, causal_text_w_pairs in enumerate(causal_relations, start=1):\n",
        "        eg_id += 1\n",
        "        num_rs = len(causal_text_w_pairs)\n",
        "        row = {\n",
        "            'corpus': 'Your Corpus Name',\n",
        "            'doc_id': 'Your Document Name',\n",
        "            'sent_id': sent_id,\n",
        "            'eg_id': eg_id,\n",
        "            'index': f'{sent_id}_{eg_id}',\n",
        "            'text': sentence,\n",
        "            'causal_text': causal_text_w_pairs,\n",
        "            'num_rs': num_rs\n",
        "        }\n",
        "        csv_data.append(row)\n",
        "\n",
        "# Write data to CSV file\n",
        "write_to_csv(csv_data, '/content/domain.csv')\n",
        "\n",
        "print(\"CSV file saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZGHYglN7cW2",
        "outputId": "6be756b9-2735-4023-e7cb-c10e31aa629a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Function to extract causal examples and format them\n",
        "def extract_causal_examples(text):\n",
        "    examples = []\n",
        "    domain_start = 0\n",
        "    while True:\n",
        "        domain_start = text.find(\"<ARG0>\", domain_start)\n",
        "        if domain_start == -1:\n",
        "            break\n",
        "\n",
        "        domain_end = text.find(\"</s>\", domain_start)\n",
        "        domain_text = text[domain_start:domain_end]\n",
        "\n",
        "        cause_start = domain_text.find(\"<ARG0>\") + len(\"<ARG0>\")\n",
        "        cause_end = domain_text.find(\"<SIG0>\")\n",
        "        cause = domain_text[cause_start:cause_end].strip()\n",
        "\n",
        "        signal_start = cause_end + len(\"<SIG0>\")\n",
        "        signal_end = domain_text.find(\"</SIG0>\")\n",
        "        signal = domain_text[signal_start:signal_end].strip()\n",
        "\n",
        "        effect_start = signal_end + len(\"</SIG0>\")\n",
        "        effect_end = domain_text.find(\"</ARG1>\")\n",
        "        effect = domain_text[effect_start:effect_end].strip()\n",
        "\n",
        "        examples.append({\n",
        "            'text': cause + ' ' + signal + ' ' + effect,\n",
        "            'causal_text': [cause, signal, effect],\n",
        "        })\n",
        "\n",
        "        domain_start = domain_end + len(\"</s>\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "# Function to write data to CSV file\n",
        "def write_to_csv(data, output_filename):\n",
        "    with open(output_filename, 'w', newline='') as csvfile:\n",
        "        fieldnames = ['text', 'causal_text']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# Read the text file\n",
        "with open('/content/generated_examples (2).txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Extract causal examples\n",
        "examples = extract_causal_examples(text)\n",
        "\n",
        "# Write data to CSV file\n",
        "write_to_csv(examples, '/content/domain.csv')\n",
        "\n",
        "print(\"CSV file saved successfully.\")"
      ],
      "metadata": {
        "id": "SGUyAHRUAYVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Load the text file\n",
        "with open('domain.txt', 'r') as file:\n",
        "    examples = file.readlines()\n",
        "\n",
        "# Concatenate the examples into a single string\n",
        "concatenated_examples = ' '.join(examples)\n",
        "\n",
        "# Split the concatenated examples by domain\n",
        "split_examples = concatenated_examples.split('*** Running model.generate:')\n",
        "\n",
        "# Remove the empty first element\n",
        "split_examples = split_examples[1:]\n",
        "\n",
        "# Open a file named 'examples.csv' in write mode\n",
        "with open('examples.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([domains, text_output])\n",
        "\n",
        "    for domain in domains:\n",
        "        # Find the example corresponding to the current domain\n",
        "        for example in split_examples:\n",
        "            if f\"in the domain of {domain}\" in example:\n",
        "                # Extract the generated output for this domain\n",
        "                _, generated_output = example.split('\\n', 1)\n",
        "                generated_output = generated_output.strip()\n",
        "\n",
        "                # Write domain name and generated output to CSV file\n",
        "                writer.writerow([domain, generated_output])\n",
        "                break  # Stop searching for this domain once found"
      ],
      "metadata": {
        "id": "UuhR5KMvaLSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prompt using the examples you have in your csv. try injecting 2, 3, 5 examples at a time and lets observe the difference by mnaual annotation of the answers\n"
      ],
      "metadata": {
        "id": "FJga49i1DhKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load examples from the CSV file\n",
        "examples_df = pd.read_csv('/content/train_subtask2_grouped.csv')\n",
        "\n",
        "# Create a function to generate prompts with varying numbers of examples\n",
        "def generate_prompt(examples, num_examples):\n",
        "    # Select the specified number of examples\n",
        "    selected_examples = examples[:num_examples]\n",
        "    prompt = \"\\n\\n\".join(selected_examples)\n",
        "    return prompt\n",
        "\n",
        "# Function to generate and print outputs for different number of examples\n",
        "def generate_outputs(examples_df, num_examples):\n",
        "    prompt = generate_prompt(examples_df['causal_text'].tolist(), num_examples)\n",
        "    print(\"Prompt:\\n\", prompt)\n",
        "    print(\"\\n*** Generating output with\", num_examples, \"examples:\")\n",
        "    output = generator(prompt)\n",
        "    print(\"Generated output:\\n\", output[0]['generated_text'])\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "# Load the text generation pipeline\n",
        "generator = pipeline(\"text-generation\")\n",
        "\n",
        "# Generate outputs for 2, 3, and 5 examples\n",
        "generate_outputs(examples_df, 2)\n",
        "#generate_outputs(examples_df, 3)\n",
        "#generate_outputs(examples_df, 5)"
      ],
      "metadata": {
        "id": "E2JX8htCAYCf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773,
          "referenced_widgets": [
            "2688769b95bb4cf2b0b983b8ccd2fae4",
            "a8cce8e445614b1781aa06e8955c08d4",
            "d5aa1b0fa71f4449a11ee04ceb082d15",
            "8c2f09851d0f4b3fae9e93a7a94e8322",
            "c4905cda5b69457fab2d7f111f94d207",
            "96e790ffdf464f92aa3be5eac7156bdd",
            "c2370a445228488092b42f30097a861c",
            "25a6b7ab345d4388a24b002668dc431b",
            "a797430caf704e17b71d0394a229a390",
            "48ebae6b37464feba91b913cd9d1c269",
            "811361ac804a4e5cb1e7881fbf28c822",
            "2ec8cd4893f940018ad9b66b1d8f7152",
            "2e71c18c37be4c6ea6d623e51fcbfe32",
            "07a4d99efa974d72a03aa77c1a9e3eeb",
            "3bff2ea10b534ad29d44f5fdfb327d3e",
            "2158338434c3428d9ee66e0f1cf94030",
            "e154ef16116945be8c27c8c2e253206a",
            "09f55bb480be44669bc4e0043d0a00ba",
            "35cb37797a714723a528e49f09f7d2ad",
            "0964c4c3fba941a893bac7adf1eeecb2",
            "8e97567b6bf74489b41dbbbb907331ab",
            "ddb7cf62ad30452589b5ca6a140b183b",
            "da0789560a4142738ac30db98f62bb8a",
            "c2b24fb1ffb94a04891a139c3217779c",
            "79b009f740a94088a813b36e970616a3",
            "564495d04b9a4421a519e69c3db4ffea",
            "9b69a116800c458482a0fb955d729dad",
            "1c904aacb5064b7da16a36a5792aa3d3",
            "35fbb7c1591f4530bb8a91d0f9f215c5",
            "936c58546bdb40728250a34431e526e0",
            "821c0a214d3f414eab73e37f1d5c6899",
            "7f7e4917d4614d399afb519dfa8f44d0",
            "6bd84e659aff46259307840b07d1a3d8",
            "454df127ff134c1cbbe12e6de891394e",
            "33b3d7ccd7d0433885fb488cc536b5bc",
            "61fe57dcc8f2462388b64e3a1a947333",
            "8c6cd11294c545a892770cf2ea55f846",
            "c4e3126142404b36ad681fcffdd6ceb2",
            "33a75e56fa54427ea0754c447e86967b",
            "443dc1bc71484c49a721e94ace716cc5",
            "524e86a4e0914b26aa8061c545c4003d",
            "bc0194e3b9eb496ebcd46b7504906fcf",
            "4f99edc8e0f04fef8ee87004b5be430b",
            "f6390d15dd384839889460e921a72f8e",
            "911ea5b8dc1844c4ba3cfce6821386b4",
            "a7a21c497e5d4f7ea5efd37beb25b8a1",
            "468812dbab654ebf979f335d0d72c856",
            "e42353a635df4d629e3c5500daf8718e",
            "da6ab6e87cd6450c9982de950d24253e",
            "741e345dc646494d923d8c7203485f89",
            "9c66c0164289441a9e0296576fe7e7ff",
            "e02334ae21b04dc7816d897779a2069f",
            "f3b017a19e014b55af9123bd1184c6f8",
            "bbfbb1cd65a345e6bea456475f10ed22",
            "8e0dabf2c0cb4c4a88fd9c1a663aac0e",
            "0cc3a459f1b94208a73348f68d523048",
            "a8ed4ae721dc41fb97ec6870ad91c0c6",
            "ea637ddedf5d4fcc8a629ce93670d706",
            "ecfed59cae6c412a82506e8fe23f2089",
            "36419db1c4e245d69509a991e9d6238d",
            "e27edd1b5cae4c20a800e66fbaf32c16",
            "95d08b11a42e44bfaa762cdf76dd74bf",
            "257f6926493d47a5a50854a46c5609f9",
            "ca1d920394ee441ba7c2c15b20e1936a",
            "cb43f8e73fb44f438481d6afac917671",
            "9e62cd4113c94f4fa6125efab412b6e9",
            "5bf644a1bac14a928f7300cf4d160420",
            "896b2a6fc14e436aa77e24c4f4e0bdea",
            "c4f3929f5179400498a21b9d58e7b375",
            "683d6301bc1944aeb96146b37f090c9c",
            "41f1b95c343041ce9cb24cd58307dc4a",
            "6bc75d8c42884362a8bff7148570a31b",
            "ddb14a355b5c4e21851b2cdf012560e7",
            "2377078535eb4e499c0b9ae01ea3f485",
            "10ed04e8bf1b4bf3863d4da6ad528f4e",
            "10d46c0ba8244af7890ed4e2a1026629",
            "f140f6bba48844839debf278dea4e59d"
          ]
        },
        "outputId": "c412844a-729c-47fb-fa56-eaf33ceea538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2688769b95bb4cf2b0b983b8ccd2fae4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec8cd4893f940018ad9b66b1d8f7152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da0789560a4142738ac30db98f62bb8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "454df127ff134c1cbbe12e6de891394e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "911ea5b8dc1844c4ba3cfce6821386b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cc3a459f1b94208a73348f68d523048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf644a1bac14a928f7300cf4d160420"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            " ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "['A decrease in interest rates</ARG0>,', 'leads to', '<ARG1>increased borrowing']\n",
            "\n",
            "*** Generating output with 2 examples:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input length of input_ids is 89, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a29e0448db8a>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Generate outputs for 2, 3, and 5 examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgenerate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#generate_outputs(examples_df, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#generate_outputs(examples_df, 5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a29e0448db8a>\u001b[0m in \u001b[0;36mgenerate_outputs\u001b[0;34m(examples_df, num_examples)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prompt:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n*** Generating output with\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"examples:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated output:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------------\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             )\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cache_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_generated_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_default_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[0;31m# 7. determine generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_ids_length\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0minput_ids_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input_ids\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1187\u001b[0m                 \u001b[0;34mf\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0;34mf\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 89, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/domain.csv')\n",
        "\n",
        "# Function to inject examples and observe manual annotations\n",
        "def inject_and_observe(num_examples):\n",
        "    # Inject examples\n",
        "    injected_examples = df.head(num_examples)\n",
        "\n",
        "    # Print injected examples\n",
        "    print(f\"\\nInjected Examples ({num_examples} examples):\")\n",
        "    for index, row in injected_examples.iterrows():\n",
        "        print(f\"Example {index + 1}:\")\n",
        "        print(f\"Text: {row['text']}\")\n",
        "        print(f\"Causal Text: {row['causal_text']}\")\n",
        "        print()  # Add a newline for better readability\n",
        "\n",
        "    # Here you would manually annotate the injected examples and observe the differences\n",
        "\n",
        "# Inject and observe 2 examples\n",
        "inject_and_observe(2)\n",
        "\n",
        "# Inject and observe 3 examples\n",
        "inject_and_observe(3)\n",
        "\n",
        "# Inject and observe 5 examples\n",
        "inject_and_observe(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Rv6PAtLfkT",
        "outputId": "5efd8bda-ffc0-4532-983b-3afaab06ba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Injected Examples (2 examples):\n",
            "Example 1:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 2:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "\n",
            "Injected Examples (3 examples):\n",
            "Example 1:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 2:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 3:\n",
            "Text: A lack of RSVPs from potential attendees. May result in.\n",
            "<ARG1> Low attendance at a social event.\n",
            "\n",
            "Example: A lack of RSVPs from potential attendees may result in low attendance at the social event.\n",
            "\n",
            "<ARG0> Poor communication between the event organizer and guests.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Confusion about the event details and location.\n",
            "\n",
            "Example: Poor communication between the event organizer and guests leads to confusion about the event details and location.\n",
            "\n",
            "<ARG0> Inadequate promotion of the event through social media and other channels.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Low awareness about the event among the target audience.\n",
            "\n",
            "Example: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\n",
            "\n",
            "<ARG0> Last-minute cancellations by key speakers or performers.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Changes in the event program and schedule.\n",
            "\n",
            "Example: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\n",
            "\n",
            "<ARG0> Poor planning and organization by the event team.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Chaos and disorganization at the event venue.\n",
            "\n",
            "Example: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\n",
            "\n",
            "In the domain of technology:\n",
            "\n",
            "<ARG0> A malfunctioning computer system.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Downtime and reduced productivity.\n",
            "\n",
            "Example: A malfunctioning computer system causes downtime and reduced productivity.\n",
            "\n",
            "<ARG0> Outdated software and hardware.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Sluggish performance and increased maintenance costs.\n",
            "\n",
            "Example: Outdated software and hardware results in sluggish performance and increased maintenance costs.\n",
            "\n",
            "<ARG0> Inadequate cybersecurity measures.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Data breaches and loss of sensitive information.\n",
            "\n",
            "Example: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\n",
            "\n",
            "<ARG0> Insufficient training for employees on new technology.\n",
            "<SIG0>\n",
            "<s> A lack of RSVPs from potential attendees.\n",
            "<SIG0> May result in.\n",
            "<ARG1> Low attendance at a social event.\n",
            "\n",
            "Example: A lack of RSVPs from potential attendees may result in low attendance at the social event.\n",
            "\n",
            "<ARG0> Poor communication between the event organizer and guests.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Confusion about the event details and location.\n",
            "\n",
            "Example: Poor communication between the event organizer and guests leads to confusion about the event details and location.\n",
            "\n",
            "<ARG0> Inadequate promotion of the event through social media and other channels.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Low awareness about the event among the target audience.\n",
            "\n",
            "Example: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\n",
            "\n",
            "<ARG0> Last-minute cancellations by key speakers or performers.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Changes in the event program and schedule.\n",
            "\n",
            "Example: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\n",
            "\n",
            "<ARG0> Poor planning and organization by the event team.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Chaos and disorganization at the event venue.\n",
            "\n",
            "Example: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\n",
            "\n",
            "In the domain of technology:\n",
            "\n",
            "<ARG0> A malfunctioning computer system.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Downtime and reduced productivity.\n",
            "\n",
            "Example: A malfunctioning computer system causes downtime and reduced productivity.\n",
            "\n",
            "<ARG0> Outdated software and hardware.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Sluggish performance and increased maintenance costs.\n",
            "\n",
            "Example: Outdated software and hardware results in sluggish performance and increased maintenance costs.\n",
            "\n",
            "<ARG0> Inadequate cybersecurity measures.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Data breaches and loss of sensitive information.\n",
            "\n",
            "Example: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\n",
            "\n",
            "<ARG0> Insufficient training for employees on new technology.\n",
            "<SIG0>\n",
            "<s>\n",
            "Causal Text: ['A lack of RSVPs from potential attendees.', 'May result in.\\n<ARG1> Low attendance at a social event.\\n\\nExample: A lack of RSVPs from potential attendees may result in low attendance at the social event.\\n\\n<ARG0> Poor communication between the event organizer and guests.\\n<SIG0> Leads to.\\n<ARG1> Confusion about the event details and location.\\n\\nExample: Poor communication between the event organizer and guests leads to confusion about the event details and location.\\n\\n<ARG0> Inadequate promotion of the event through social media and other channels.\\n<SIG0> Results in.\\n<ARG1> Low awareness about the event among the target audience.\\n\\nExample: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\\n\\n<ARG0> Last-minute cancellations by key speakers or performers.\\n<SIG0> Causes.\\n<ARG1> Changes in the event program and schedule.\\n\\nExample: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\\n\\n<ARG0> Poor planning and organization by the event team.\\n<SIG0> Results in.\\n<ARG1> Chaos and disorganization at the event venue.\\n\\nExample: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\\n\\nIn the domain of technology:\\n\\n<ARG0> A malfunctioning computer system.\\n<SIG0> Causes.\\n<ARG1> Downtime and reduced productivity.\\n\\nExample: A malfunctioning computer system causes downtime and reduced productivity.\\n\\n<ARG0> Outdated software and hardware.\\n<SIG0> Results in.\\n<ARG1> Sluggish performance and increased maintenance costs.\\n\\nExample: Outdated software and hardware results in sluggish performance and increased maintenance costs.\\n\\n<ARG0> Inadequate cybersecurity measures.\\n<SIG0> Leads to.\\n<ARG1> Data breaches and loss of sensitive information.\\n\\nExample: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\\n\\n<ARG0> Insufficient training for employees on new technology.\\n<SIG0>\\n<s>', 'A lack of RSVPs from potential attendees.\\n<SIG0> May result in.\\n<ARG1> Low attendance at a social event.\\n\\nExample: A lack of RSVPs from potential attendees may result in low attendance at the social event.\\n\\n<ARG0> Poor communication between the event organizer and guests.\\n<SIG0> Leads to.\\n<ARG1> Confusion about the event details and location.\\n\\nExample: Poor communication between the event organizer and guests leads to confusion about the event details and location.\\n\\n<ARG0> Inadequate promotion of the event through social media and other channels.\\n<SIG0> Results in.\\n<ARG1> Low awareness about the event among the target audience.\\n\\nExample: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\\n\\n<ARG0> Last-minute cancellations by key speakers or performers.\\n<SIG0> Causes.\\n<ARG1> Changes in the event program and schedule.\\n\\nExample: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\\n\\n<ARG0> Poor planning and organization by the event team.\\n<SIG0> Results in.\\n<ARG1> Chaos and disorganization at the event venue.\\n\\nExample: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\\n\\nIn the domain of technology:\\n\\n<ARG0> A malfunctioning computer system.\\n<SIG0> Causes.\\n<ARG1> Downtime and reduced productivity.\\n\\nExample: A malfunctioning computer system causes downtime and reduced productivity.\\n\\n<ARG0> Outdated software and hardware.\\n<SIG0> Results in.\\n<ARG1> Sluggish performance and increased maintenance costs.\\n\\nExample: Outdated software and hardware results in sluggish performance and increased maintenance costs.\\n\\n<ARG0> Inadequate cybersecurity measures.\\n<SIG0> Leads to.\\n<ARG1> Data breaches and loss of sensitive information.\\n\\nExample: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\\n\\n<ARG0> Insufficient training for employees on new technology.\\n<SIG0>\\n<s>']\n",
            "\n",
            "\n",
            "Injected Examples (5 examples):\n",
            "Example 1:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 2:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 3:\n",
            "Text: A lack of RSVPs from potential attendees. May result in.\n",
            "<ARG1> Low attendance at a social event.\n",
            "\n",
            "Example: A lack of RSVPs from potential attendees may result in low attendance at the social event.\n",
            "\n",
            "<ARG0> Poor communication between the event organizer and guests.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Confusion about the event details and location.\n",
            "\n",
            "Example: Poor communication between the event organizer and guests leads to confusion about the event details and location.\n",
            "\n",
            "<ARG0> Inadequate promotion of the event through social media and other channels.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Low awareness about the event among the target audience.\n",
            "\n",
            "Example: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\n",
            "\n",
            "<ARG0> Last-minute cancellations by key speakers or performers.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Changes in the event program and schedule.\n",
            "\n",
            "Example: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\n",
            "\n",
            "<ARG0> Poor planning and organization by the event team.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Chaos and disorganization at the event venue.\n",
            "\n",
            "Example: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\n",
            "\n",
            "In the domain of technology:\n",
            "\n",
            "<ARG0> A malfunctioning computer system.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Downtime and reduced productivity.\n",
            "\n",
            "Example: A malfunctioning computer system causes downtime and reduced productivity.\n",
            "\n",
            "<ARG0> Outdated software and hardware.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Sluggish performance and increased maintenance costs.\n",
            "\n",
            "Example: Outdated software and hardware results in sluggish performance and increased maintenance costs.\n",
            "\n",
            "<ARG0> Inadequate cybersecurity measures.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Data breaches and loss of sensitive information.\n",
            "\n",
            "Example: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\n",
            "\n",
            "<ARG0> Insufficient training for employees on new technology.\n",
            "<SIG0>\n",
            "<s> A lack of RSVPs from potential attendees.\n",
            "<SIG0> May result in.\n",
            "<ARG1> Low attendance at a social event.\n",
            "\n",
            "Example: A lack of RSVPs from potential attendees may result in low attendance at the social event.\n",
            "\n",
            "<ARG0> Poor communication between the event organizer and guests.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Confusion about the event details and location.\n",
            "\n",
            "Example: Poor communication between the event organizer and guests leads to confusion about the event details and location.\n",
            "\n",
            "<ARG0> Inadequate promotion of the event through social media and other channels.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Low awareness about the event among the target audience.\n",
            "\n",
            "Example: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\n",
            "\n",
            "<ARG0> Last-minute cancellations by key speakers or performers.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Changes in the event program and schedule.\n",
            "\n",
            "Example: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\n",
            "\n",
            "<ARG0> Poor planning and organization by the event team.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Chaos and disorganization at the event venue.\n",
            "\n",
            "Example: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\n",
            "\n",
            "In the domain of technology:\n",
            "\n",
            "<ARG0> A malfunctioning computer system.\n",
            "<SIG0> Causes.\n",
            "<ARG1> Downtime and reduced productivity.\n",
            "\n",
            "Example: A malfunctioning computer system causes downtime and reduced productivity.\n",
            "\n",
            "<ARG0> Outdated software and hardware.\n",
            "<SIG0> Results in.\n",
            "<ARG1> Sluggish performance and increased maintenance costs.\n",
            "\n",
            "Example: Outdated software and hardware results in sluggish performance and increased maintenance costs.\n",
            "\n",
            "<ARG0> Inadequate cybersecurity measures.\n",
            "<SIG0> Leads to.\n",
            "<ARG1> Data breaches and loss of sensitive information.\n",
            "\n",
            "Example: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\n",
            "\n",
            "<ARG0> Insufficient training for employees on new technology.\n",
            "<SIG0>\n",
            "<s>\n",
            "Causal Text: ['A lack of RSVPs from potential attendees.', 'May result in.\\n<ARG1> Low attendance at a social event.\\n\\nExample: A lack of RSVPs from potential attendees may result in low attendance at the social event.\\n\\n<ARG0> Poor communication between the event organizer and guests.\\n<SIG0> Leads to.\\n<ARG1> Confusion about the event details and location.\\n\\nExample: Poor communication between the event organizer and guests leads to confusion about the event details and location.\\n\\n<ARG0> Inadequate promotion of the event through social media and other channels.\\n<SIG0> Results in.\\n<ARG1> Low awareness about the event among the target audience.\\n\\nExample: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\\n\\n<ARG0> Last-minute cancellations by key speakers or performers.\\n<SIG0> Causes.\\n<ARG1> Changes in the event program and schedule.\\n\\nExample: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\\n\\n<ARG0> Poor planning and organization by the event team.\\n<SIG0> Results in.\\n<ARG1> Chaos and disorganization at the event venue.\\n\\nExample: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\\n\\nIn the domain of technology:\\n\\n<ARG0> A malfunctioning computer system.\\n<SIG0> Causes.\\n<ARG1> Downtime and reduced productivity.\\n\\nExample: A malfunctioning computer system causes downtime and reduced productivity.\\n\\n<ARG0> Outdated software and hardware.\\n<SIG0> Results in.\\n<ARG1> Sluggish performance and increased maintenance costs.\\n\\nExample: Outdated software and hardware results in sluggish performance and increased maintenance costs.\\n\\n<ARG0> Inadequate cybersecurity measures.\\n<SIG0> Leads to.\\n<ARG1> Data breaches and loss of sensitive information.\\n\\nExample: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\\n\\n<ARG0> Insufficient training for employees on new technology.\\n<SIG0>\\n<s>', 'A lack of RSVPs from potential attendees.\\n<SIG0> May result in.\\n<ARG1> Low attendance at a social event.\\n\\nExample: A lack of RSVPs from potential attendees may result in low attendance at the social event.\\n\\n<ARG0> Poor communication between the event organizer and guests.\\n<SIG0> Leads to.\\n<ARG1> Confusion about the event details and location.\\n\\nExample: Poor communication between the event organizer and guests leads to confusion about the event details and location.\\n\\n<ARG0> Inadequate promotion of the event through social media and other channels.\\n<SIG0> Results in.\\n<ARG1> Low awareness about the event among the target audience.\\n\\nExample: Inadequate promotion of the event through social media and other channels results in low awareness about the event among the target audience.\\n\\n<ARG0> Last-minute cancellations by key speakers or performers.\\n<SIG0> Causes.\\n<ARG1> Changes in the event program and schedule.\\n\\nExample: Last-minute cancellations by key speakers or performers causes changes in the event program and schedule.\\n\\n<ARG0> Poor planning and organization by the event team.\\n<SIG0> Results in.\\n<ARG1> Chaos and disorganization at the event venue.\\n\\nExample: Poor planning and organization by the event team results in chaos and disorganization at the event venue.\\n\\nIn the domain of technology:\\n\\n<ARG0> A malfunctioning computer system.\\n<SIG0> Causes.\\n<ARG1> Downtime and reduced productivity.\\n\\nExample: A malfunctioning computer system causes downtime and reduced productivity.\\n\\n<ARG0> Outdated software and hardware.\\n<SIG0> Results in.\\n<ARG1> Sluggish performance and increased maintenance costs.\\n\\nExample: Outdated software and hardware results in sluggish performance and increased maintenance costs.\\n\\n<ARG0> Inadequate cybersecurity measures.\\n<SIG0> Leads to.\\n<ARG1> Data breaches and loss of sensitive information.\\n\\nExample: Inadequate cybersecurity measures leads to data breaches and loss of sensitive information.\\n\\n<ARG0> Insufficient training for employees on new technology.\\n<SIG0>\\n<s>']\n",
            "\n",
            "Example 4:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n",
            "Example 5:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Causal Text: ['and </ARG0>.\\n  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\\n  Signal: Words that transition the cause to the effect, to be enclosed between', 'and', '']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EqxiDUOVxc7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenation of the previous dataset and the new dataset\n",
        "# Load the previous dataset\n",
        "import pandas as pd\n",
        "previous_df = pd.read_csv('/content/drive/MyDrive/Semester Project/Data/train_subtask2_grouped.csv')\n",
        "print(previous_df.shape)\n",
        "\n",
        "# Load the new dataset\n",
        "new_df = pd.read_csv('/content/domain.csv')\n",
        "\n",
        "# Concatenate the previous and new datasets\n",
        "concatenated_df = pd.concat([previous_df, new_df], ignore_index=True)\n",
        "\n",
        "# Save the concatenated dataset to a new CSV file\n",
        "concatenated_df.to_csv('concatenated_dataset.csv', index=False)\n",
        "print(concatenated_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKWRHAYguZfr",
        "outputId": "6478368f-2736-462e-9c74-2fe0dceabd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3075, 8)\n",
            "(3094, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking manually if there's a causal relation in the text:\n"
      ],
      "metadata": {
        "id": "VoRDEKIt3CFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def manual_check_causal_relation(df):\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"\\nExample {index + 1}:\")\n",
        "        print(f\"Text: {row['text']}\")\n",
        "        causal_relation = input(\"Does this example contain a causal relation? (Yes/No): \").strip().lower()\n",
        "        while causal_relation not in ['yes', 'no']:\n",
        "            print(\"Invalid input. Please enter 'Yes' or 'No'.\")\n",
        "            causal_relation = input(\"Does this example contain a causal relation? (Yes/No): \").strip().lower()\n",
        "        df.at[index, 'causal_relation'] = causal_relation\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/domain.csv')\n",
        "\n",
        "# Add a column for manual annotations\n",
        "df['causal_relation'] = \"\"\n",
        "\n",
        "# Manually check causal relations\n",
        "df = manual_check_causal_relation(df)\n",
        "\n",
        "# Save the annotated dataset\n",
        "df.to_csv('annotated_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RG0w7va3H-6",
        "outputId": "d783e27f-d234-4434-f116-6d0d4605fe0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 1:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 2:\n",
            "Text: The increase in interest rates by the Federal Reserve resulted in a decrease in borrowing and spending, leading to a decline in economic activity, < as evidenced by a decrease in GDP growth and an increase in unemployment, <ARG1>.\n",
            "\n",
            "<ARG0> The implementation of a minimum wage law caused a rise in labor costs for businesses, <SIG0> resulting in some companies reducing their workforce or relocating to areas with lower labor costs, <</SIG0> ultimately leading to a net decrease in employment, <ARG1>.\n",
            "\n",
            "<ARG0> The deregulation of certain industries led to increased competition and innovation, <SIG0> driving down prices and improving the overall quality of goods and services, <</SIG0> resulting in a boost in consumer demand and economic growth, <ARG1>.\n",
            "\n",
            "<ARG0> The imposition of trade barriers such as tariffs and quotas resulted in retaliatory actions from other countries, <SIG0> causing a decrease in international trade and a corresponding decline in economic activity, <</SIG0> with negative impacts on industries and businesses that rely on global commerce, <ARG1>.\n",
            "\n",
            "<ARG0> The introduction of a new technology or product caused a shift in consumer preferences, <SIG0> leading to a decline in demand for older, less efficient alternatives, <</SIG0> ultimately resulting in the closure of traditional businesses and a rise in the market share of innovative companies, <ARG1>\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 3:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 4:\n",
            "Text: The lack of communication between the event planner and the catering company caused the menu to be inadequate. As a result,\n",
            "<ARG1> The guests were disappointed with the food selection.\n",
            "\n",
            "<ARG0> The sudden rainstorm forced the outdoor event to be moved indoors.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The guests had to squeeze into the smaller venue.\n",
            "\n",
            "<ARG0> The failure to send out invitations on time resulted in a low turnout at the gala.\n",
            "<SIG0> Consequently,\n",
            "<ARG1> The organizers had to cut costs due to the lack of attendees.\n",
            "\n",
            "<ARG0> The poor sound quality at the concert was caused by the faulty equipment.\n",
            "<SIG0> Hence,\n",
            "<ARG1> The audience had difficulty hearing the performers.\n",
            "\n",
            "<ARG0> The absence of a backup plan caused the event to be cancelled due to unforeseen circumstances.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The guests were left disappointed and disappointed in the organization's lack of foresight The lack of communication between the event planner and the catering company caused the menu to be inadequate.\n",
            "<SIG0> As a result,\n",
            "<ARG1> The guests were disappointed with the food selection.\n",
            "\n",
            "<ARG0> The sudden rainstorm forced the outdoor event to be moved indoors.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The guests had to squeeze into the smaller venue.\n",
            "\n",
            "<ARG0> The failure to send out invitations on time resulted in a low turnout at the gala.\n",
            "<SIG0> Consequently,\n",
            "<ARG1> The organizers had to cut costs due to the lack of attendees.\n",
            "\n",
            "<ARG0> The poor sound quality at the concert was caused by the faulty equipment.\n",
            "<SIG0> Hence,\n",
            "<ARG1> The audience had difficulty hearing the performers.\n",
            "\n",
            "<ARG0> The absence of a backup plan caused the event to be cancelled due to unforeseen circumstances.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The guests were left disappointed and disappointed in the organization's lack of foresight\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 5:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 6:\n",
            "Text: A lack of economic opportunities and high levels of poverty can lead to political unrest, as people become disillusioned with the government's inability to address their basic needs and may turn to protests and demonstrations to demand change. This situation can escalate into more serious forms of political instability, such as riots, strikes, and civil disobedience, if the government fails to respond to the people's demands or uses excessive force to suppress them.\n",
            "<ARG1> The result of political unrest can be a destabilization of the political system, as the government's legitimacy is called into question and its ability to maintain order is undermined. This can lead to a breakdown of law and order, as well as a rise in violence and chaos.\n",
            "<SIG0> In extreme cases, political unrest can even lead to the overthrow of the government or the emergence of a new political order. However, it is important to note that political unrest is not always a negative outcome, as it can also lead to positive change and reforms, if the government is willing to listen to the people's grievances and respond in a constructive manner.\n",
            "<ARG0> The actions of authoritarian leaders, who suppress dissent and restrict fundamental freedoms, can also lead to political unrest, as people become frustrated with the lack of democratic processes and the lack of accountability in the government.\n",
            "<SIG0> This situation can escalate into mass protests, as people demand greater freedom and democracy, and may even lead to international condemnation and economic sanctions, if the government's actions are seen as a threat to human rights and democratic values.\n",
            "<ARG1> The result of political unrest caused by authoritarian leaders can be a change in the political system, as people demand greater democracy, rule of law, and accountability. This can lead to the establishment of new democratic institutions, the adoption of more liberal policies, and the emergence of a more open and transparent political system.\n",
            "<SIG0> However, it is important to note that political unrest caused by authoritarian leaders can also lead to a backlash, as the government may respond with greater repression and violence, in an attempt to maintain its grip on power. This can further escalate the situation and make it more difficult to achieve a peaceful resolution to the conflict A lack of economic opportunities and high levels of poverty can lead to political unrest, as people become disillusioned with the government's inability to address their basic needs and may turn to protests and demonstrations to demand change.\n",
            "<SIG0> This situation can escalate into more serious forms of political instability, such as riots, strikes, and civil disobedience, if the government fails to respond to the people's demands or uses excessive force to suppress them.\n",
            "<ARG1> The result of political unrest can be a destabilization of the political system, as the government's legitimacy is called into question and its ability to maintain order is undermined. This can lead to a breakdown of law and order, as well as a rise in violence and chaos.\n",
            "<SIG0> In extreme cases, political unrest can even lead to the overthrow of the government or the emergence of a new political order. However, it is important to note that political unrest is not always a negative outcome, as it can also lead to positive change and reforms, if the government is willing to listen to the people's grievances and respond in a constructive manner.\n",
            "<ARG0> The actions of authoritarian leaders, who suppress dissent and restrict fundamental freedoms, can also lead to political unrest, as people become frustrated with the lack of democratic processes and the lack of accountability in the government.\n",
            "<SIG0> This situation can escalate into mass protests, as people demand greater freedom and democracy, and may even lead to international condemnation and economic sanctions, if the government's actions are seen as a threat to human rights and democratic values.\n",
            "<ARG1> The result of political unrest caused by authoritarian leaders can be a change in the political system, as people demand greater democracy, rule of law, and accountability. This can lead to the establishment of new democratic institutions, the adoption of more liberal policies, and the emergence of a more open and transparent political system.\n",
            "<SIG0> However, it is important to note that political unrest caused by authoritarian leaders can also lead to a backlash, as the government may respond with greater repression and violence, in an attempt to maintain its grip on power. This can further escalate the situation and make it more difficult to achieve a peaceful resolution to the conflict\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 7:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 8:\n",
            "Text: The low voter turnout in the recent election. Led to.\n",
            "<ARG1> The victory of the incumbent president.\n",
            "\n",
            "<ARG0> The high level of corruption in the ruling party.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> The defeat of the ruling party in the elections.\n",
            "\n",
            "<ARG0> The failure of the opposition party to present a strong candidate.\n",
            "<SIG0> Caused.\n",
            "<ARG1> The landslide victory of the ruling party in the elections.\n",
            "\n",
            "<ARG0> The lack of enthusiasm among the voters due to the pandemic.\n",
            "<SIG0> Led to.\n",
            "<ARG1> The low voter turnout in the elections.\n",
            "\n",
            "<ARG0> The effective campaigning by the opposition party.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> The narrow defeat of the ruling party in the elections The low voter turnout in the recent election.\n",
            "<SIG0> Led to.\n",
            "<ARG1> The victory of the incumbent president.\n",
            "\n",
            "<ARG0> The high level of corruption in the ruling party.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> The defeat of the ruling party in the elections.\n",
            "\n",
            "<ARG0> The failure of the opposition party to present a strong candidate.\n",
            "<SIG0> Caused.\n",
            "<ARG1> The landslide victory of the ruling party in the elections.\n",
            "\n",
            "<ARG0> The lack of enthusiasm among the voters due to the pandemic.\n",
            "<SIG0> Led to.\n",
            "<ARG1> The low voter turnout in the elections.\n",
            "\n",
            "<ARG0> The effective campaigning by the opposition party.\n",
            "<SIG0> Resulted in.\n",
            "<ARG1> The narrow defeat of the ruling party in the elections\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 9:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 10:\n",
            "Text: An intense heatwave in India caused <ARG1> massive power outages, due to the failure of power plants and transmission lines in the scorching heat.\n",
            "\n",
            "<ARG0> Heavy rains in the Philippines led to <ARG1> widespread flooding, <SIG0> as the overburdened drainage systems and levees were unable to cope with the deluge.\n",
            "\n",
            "<ARG0> The eruption of the Mount Agung volcano in Indonesia caused <ARG1> thousands of people to evacuate, <SIG0> as the ash and smoke billowed into the air, making it difficult to breathe and see.\n",
            "\n",
            "<ARG0> The 2011 earthquake and tsunami in Japan triggered <ARG1> a nuclear crisis, <SIG0> as the Fukushima Daiichi power plant was damaged, releasing radiation into the environment.\n",
            "\n",
            "<ARG0> The Hurricane Katrina disaster in the US resulted in <ARG1> widespread destruction, <SIG0> as the powerful storm surges and winds ravaged the city of New Orleans and its surroundings An intense heatwave in India caused <ARG1> massive power outages, <SIG0> due to the failure of power plants and transmission lines in the scorching heat.\n",
            "\n",
            "<ARG0> Heavy rains in the Philippines led to <ARG1> widespread flooding, <SIG0> as the overburdened drainage systems and levees were unable to cope with the deluge.\n",
            "\n",
            "<ARG0> The eruption of the Mount Agung volcano in Indonesia caused <ARG1> thousands of people to evacuate, <SIG0> as the ash and smoke billowed into the air, making it difficult to breathe and see.\n",
            "\n",
            "<ARG0> The 2011 earthquake and tsunami in Japan triggered <ARG1> a nuclear crisis, <SIG0> as the Fukushima Daiichi power plant was damaged, releasing radiation into the environment.\n",
            "\n",
            "<ARG0> The Hurricane Katrina disaster in the US resulted in <ARG1> widespread destruction, <SIG0> as the powerful storm surges and winds ravaged the city of New Orleans and its surroundings\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 11:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 12:\n",
            "Text: An excessive speed of a vehicle while driving on a slippery road leads to a loss of control over the vehicle, resulting in <ARG1> a car accident.\n",
            "<ARG0> Failure of a driver to maintain a safe distance from the vehicle in front of him in a heavy traffic causes <SIG0> a rear-end collision, resulting in <ARG1> vehicular damages and injuries.\n",
            "<ARG0> Ignoring the traffic signals or disobeying the traffic rules results in <SIG0> a traffic violation, which may cause <ARG1> a traffic fine, imprisonment or suspension of the driving license.\n",
            "<ARG0> Negligence of the driver to wear seat belts while driving a vehicle causes <SIG0> a sudden jerk to the passengers in case of a mishap, resulting in <ARG1> serious injuries or fatal accidents.\n",
            "<ARG0> Defects in the brakes or steering mechanism of a vehicle due to lack of regular maintenance results in <SIG0> the loss of control over the vehicle, resulting in <ARG1> accidents and injuries An excessive speed of a vehicle while driving on a slippery road leads to <SIG0> a loss of control over the vehicle, resulting in <ARG1> a car accident.\n",
            "<ARG0> Failure of a driver to maintain a safe distance from the vehicle in front of him in a heavy traffic causes <SIG0> a rear-end collision, resulting in <ARG1> vehicular damages and injuries.\n",
            "<ARG0> Ignoring the traffic signals or disobeying the traffic rules results in <SIG0> a traffic violation, which may cause <ARG1> a traffic fine, imprisonment or suspension of the driving license.\n",
            "<ARG0> Negligence of the driver to wear seat belts while driving a vehicle causes <SIG0> a sudden jerk to the passengers in case of a mishap, resulting in <ARG1> serious injuries or fatal accidents.\n",
            "<ARG0> Defects in the brakes or steering mechanism of a vehicle due to lack of regular maintenance results in <SIG0> the loss of control over the vehicle, resulting in <ARG1> accidents and injuries\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 13:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 14:\n",
            "Text: A person's decision to commit a crime is caused by a variety of factors such as poverty, lack of education, and social inequality. These factors create a cycle of deprivation and despair that drives individuals towards criminal activity as a means of survival. The effects of this cycle can be seen in the high rates of crime in impoverished communities, where people are forced to turn to criminal activity as a way to provide for themselves and their families. The signal between cause and effect is the decision to engage in criminal behavior, which is often a rational response to the circumstances in which a person finds themselves.\n",
            "\n",
            "<ARG1> The effects of this decision can be devastating, leading to imprisonment, financial ruin, and social isolation. The cycle of deprivation and despair continues, as those who have been incarcerated find it difficult to secure employment and housing upon release, further contributing to their economic and social disadvantage. The signal between cause and effect is the decision to continue engaging in criminal behavior, which is often a result of the lack of opportunities and resources available to those who have been disproportionately affected by poverty, lack of education, and social inequality.\n",
            "\n",
            "<ARG0> The use of drugs and alcohol is a common cause of criminal activity, as individuals turn to these substances as a way to escape from the challenges and hardships of daily life. The effects of drug and alcohol use can be seen in the high rates of property crimes and violent offenses committed by those who are under the influence. The signal between cause and effect is the decision to use drugs and alcohol, which can lead to impaired judgment, decreased inhibitions, and a heightened sense of risk-taking behavior.\n",
            "\n",
            "<ARG1> The effects of drug and alcohol use can also include addiction, which can drive individuals to engage in criminal activity in order to fund their habits. This cycle can be difficult to break, as those who are addicted may find it challenging to secure employment and housing due to their criminal history. The signal between cause and effect is the decision to continue using drugs and alcohol, which can lead to a cycle of addiction, criminal behavior, and social isolation.\n",
            "\n",
            "<ARG0> The presence of gangs and organized criminal networks is a common cause of violent crime, as these groups seek to control territory, resources, and economic opportunities through the use of force and intimidation. The effects of gang and organized criminal activity can be seen in the high\n",
            "<s> > A person's decision to commit a crime is caused by a variety of factors such as poverty, lack of education, and social inequality. These factors create a cycle of deprivation and despair that drives individuals towards criminal activity as a means of survival. The effects of this cycle can be seen in the high rates of crime in impoverished communities, where people are forced to turn to criminal activity as a way to provide for themselves and their families. The signal between cause and effect is the decision to engage in criminal behavior, which is often a rational response to the circumstances in which a person finds themselves.\n",
            "\n",
            "<ARG1> The effects of this decision can be devastating, leading to imprisonment, financial ruin, and social isolation. The cycle of deprivation and despair continues, as those who have been incarcerated find it difficult to secure employment and housing upon release, further contributing to their economic and social disadvantage. The signal between cause and effect is the decision to continue engaging in criminal behavior, which is often a result of the lack of opportunities and resources available to those who have been disproportionately affected by poverty, lack of education, and social inequality.\n",
            "\n",
            "<ARG0> The use of drugs and alcohol is a common cause of criminal activity, as individuals turn to these substances as a way to escape from the challenges and hardships of daily life. The effects of drug and alcohol use can be seen in the high rates of property crimes and violent offenses committed by those who are under the influence. The signal between cause and effect is the decision to use drugs and alcohol, which can lead to impaired judgment, decreased inhibitions, and a heightened sense of risk-taking behavior.\n",
            "\n",
            "<ARG1> The effects of drug and alcohol use can also include addiction, which can drive individuals to engage in criminal activity in order to fund their habits. This cycle can be difficult to break, as those who are addicted may find it challenging to secure employment and housing due to their criminal history. The signal between cause and effect is the decision to continue using drugs and alcohol, which can lead to a cycle of addiction, criminal behavior, and social isolation.\n",
            "\n",
            "<ARG0> The presence of gangs and organized criminal networks is a common cause of violent crime, as these groups seek to control territory, resources, and economic opportunities through the use of force and intimidation. The effects of gang and organized criminal activity can be seen in the high\n",
            "<s> A person's decision to commit a crime is caused by a variety of factors such as poverty, lack of education, and social inequality. These factors create a cycle of deprivation and despair that drives individuals towards criminal activity as a means of survival. The effects of this cycle can be seen in the high rates of crime in impoverished communities, where people are forced to turn to criminal activity as a way to provide for themselves and their families. The signal between cause and effect is the decision to engage in criminal behavior, which is often a rational response to the circumstances in which a person finds themselves.\n",
            "\n",
            "<ARG1> The effects of this decision can be devastating, leading to imprisonment, financial ruin, and social isolation. The cycle of deprivation and despair continues, as those who have been incarcerated find it difficult to secure employment and housing upon release, further contributing to their economic and social disadvantage. The signal between cause and effect is the decision to continue engaging in criminal behavior, which is often a result of the lack of opportunities and resources available to those who have been disproportionately affected by poverty, lack of education, and social inequality.\n",
            "\n",
            "<ARG0> The use of drugs and alcohol is a common cause of criminal activity, as individuals turn to these substances as a way to escape from the challenges and hardships of daily life. The effects of drug and alcohol use can be seen in the high rates of property crimes and violent offenses committed by those who are under the influence. The signal between cause and effect is the decision to use drugs and alcohol, which can lead to impaired judgment, decreased inhibitions, and a heightened sense of risk-taking behavior.\n",
            "\n",
            "<ARG1> The effects of drug and alcohol use can also include addiction, which can drive individuals to engage in criminal activity in order to fund their habits. This cycle can be difficult to break, as those who are addicted may find it challenging to secure employment and housing due to their criminal history. The signal between cause and effect is the decision to continue using drugs and alcohol, which can lead to a cycle of addiction, criminal behavior, and social isolation.\n",
            "\n",
            "<ARG0> The presence of gangs and organized criminal networks is a common cause of violent crime, as these groups seek to control territory, resources, and economic opportunities through the use of force and intimidation. The effects of gang and organized criminal activity can be seen in the high\n",
            "<s>\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 15:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 16:\n",
            "Text: An unsecured chemical container tipped over due to a forklift collision, </ARG0> resulting in <ARG1> the release of toxic fumes\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 17:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 18:\n",
            "Text: The rise of China as an economic superpower has led to increased competition in the global market, which has resulted in a decline in the market share of some Western countries. This trend has been further exacerbated by China's Belt and Road Initiative, which has enabled the country to expand its economic influence in Asia and beyond. <ARG1> As a result, some Western countries have responded with their own infrastructure initiatives, such as the European Union's New Silk Road project, in an effort to counter China's growing economic power. <SIG0> However, some critics argue that these initiatives may lead to increased debt and corruption in recipient countries, further fueling China's economic dominance The rise of China as an economic superpower has led to increased competition in the global market, which has resulted in a decline in the market share of some Western countries. <SIG0> This trend has been further exacerbated by China's Belt and Road Initiative, which has enabled the country to expand its economic influence in Asia and beyond. <ARG1> As a result, some Western countries have responded with their own infrastructure initiatives, such as the European Union's New Silk Road project, in an effort to counter China's growing economic power. <SIG0> However, some critics argue that these initiatives may lead to increased debt and corruption in recipient countries, further fueling China's economic dominance\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 19:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 20:\n",
            "Text: The government implemented a new housing policy in response to the increasing demand for affordable housing. In order to address the housing crisis,\n",
            "<ARG1> The government has allocated more funds for social housing construction.\n",
            "\n",
            "<ARG0> The local council implemented a new waste management system in response to increasing pollution levels.\n",
            "<SIG0> In order to reduce pollution,\n",
            "<ARG1> The council introduced a recycling program that requires households to separate their waste into three categories: recyclable, compostable, and landfill.\n",
            "\n",
            "<ARG0> The government introduced a new tax policy to address the issue of income inequality.\n",
            "<SIG0> In order to promote social justice,\n",
            "<ARG1> The government increased taxes on the wealthiest citizens to fund social welfare programs for low-income families.\n",
            "\n",
            "<ARG0> The government passed a new law to address the issue of climate change.\n",
            "<SIG0> In order to mitigate the effects of global warming,\n",
            "<ARG1> The law mandated a transition to renewable energy sources and set targets for reducing greenhouse gas emissions.\n",
            "\n",
            "<ARG0> The government implemented a new education policy to address the issue of underperforming schools.\n",
            "<SIG0> In order to improve educational outcomes,\n",
            "<ARG1> The government provided additional funding to schools in low-income areas and introduced reforms to teacher training and curriculum development The government implemented a new housing policy in response to the increasing demand for affordable housing.\n",
            "<SIG0> In order to address the housing crisis,\n",
            "<ARG1> The government has allocated more funds for social housing construction.\n",
            "\n",
            "<ARG0> The local council implemented a new waste management system in response to increasing pollution levels.\n",
            "<SIG0> In order to reduce pollution,\n",
            "<ARG1> The council introduced a recycling program that requires households to separate their waste into three categories: recyclable, compostable, and landfill.\n",
            "\n",
            "<ARG0> The government introduced a new tax policy to address the issue of income inequality.\n",
            "<SIG0> In order to promote social justice,\n",
            "<ARG1> The government increased taxes on the wealthiest citizens to fund social welfare programs for low-income families.\n",
            "\n",
            "<ARG0> The government passed a new law to address the issue of climate change.\n",
            "<SIG0> In order to mitigate the effects of global warming,\n",
            "<ARG1> The law mandated a transition to renewable energy sources and set targets for reducing greenhouse gas emissions.\n",
            "\n",
            "<ARG0> The government implemented a new education policy to address the issue of underperforming schools.\n",
            "<SIG0> In order to improve educational outcomes,\n",
            "<ARG1> The government provided additional funding to schools in low-income areas and introduced reforms to teacher training and curriculum development\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 21:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 22:\n",
            "Text: The high temperature caused the ice cream to melt. As a result,\n",
            "<ARG1> The ice cream became a runny mess.\n",
            "\n",
            "<ARG0> The lack of sleep led to the employee's decreased productivity.\n",
            "<SIG0> Consequently,\n",
            "<ARG1> The company's profits suffered a significant decline.\n",
            "\n",
            "<ARG0> The driver's failure to yield resulted in a fatal car accident.\n",
            "<SIG0> Subsequently,\n",
            "<ARG1> The driver was charged with vehicular manslaughter.\n",
            "\n",
            "<ARG0> The bacteria's resistance to antibiotics contributed to the spread of infectious diseases.\n",
            "<SIG0> Hence,\n",
            "<ARG1> Medical treatments for these diseases became more difficult to develop.\n",
            "\n",
            "<ARG0> The excessive rainfall caused the river to overflow.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The nearby towns were evacuated due to the risk of flooding The high temperature caused the ice cream to melt.\n",
            "<SIG0> As a result,\n",
            "<ARG1> The ice cream became a runny mess.\n",
            "\n",
            "<ARG0> The lack of sleep led to the employee's decreased productivity.\n",
            "<SIG0> Consequently,\n",
            "<ARG1> The company's profits suffered a significant decline.\n",
            "\n",
            "<ARG0> The driver's failure to yield resulted in a fatal car accident.\n",
            "<SIG0> Subsequently,\n",
            "<ARG1> The driver was charged with vehicular manslaughter.\n",
            "\n",
            "<ARG0> The bacteria's resistance to antibiotics contributed to the spread of infectious diseases.\n",
            "<SIG0> Hence,\n",
            "<ARG1> Medical treatments for these diseases became more difficult to develop.\n",
            "\n",
            "<ARG0> The excessive rainfall caused the river to overflow.\n",
            "<SIG0> Therefore,\n",
            "<ARG1> The nearby towns were evacuated due to the risk of flooding\n",
            "Does this example contain a causal relation? (Yes/No): yes\n",
            "\n",
            "Example 23:\n",
            "Text: and </ARG0>.\n",
            "  Effect: The event that occurs due to the cause, to be enclosed between <ARG1> and </ARG1>.\n",
            "  Signal: Words that transition the cause to the effect, to be enclosed between and \n",
            "Does this example contain a causal relation? (Yes/No): no\n",
            "\n",
            "Example 24:\n",
            "Text: The decision to launch a military operation in Afghanistan was made by President Obama due to the increasing threat posed by the Taliban and Al Qaeda, resulting in the deployment of thousands of U.S. Troops to the region. <ARG1> This military intervention has, in turn, had a significant impact on the region's political and social landscape, with some positive developments such as increased stability and economic growth, but also negative consequences including civilian casualties and ongoing conflict The decision to launch a military operation in Afghanistan was made by President Obama due to the increasing threat posed by the Taliban and Al Qaeda, <SIG0> resulting in the deployment of thousands of U.S. Troops to the region. <ARG1> This military intervention has, in turn, had a significant impact on the region's political and social landscape, with some positive developments such as increased stability and economic growth, but also negative consequences including civilian casualties and ongoing conflict\n",
            "Does this example contain a causal relation? (Yes/No): yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the annotated dataset\n",
        "df = pd.read_csv('annotated_dataset.csv')\n",
        "\n",
        "# Check for NaN values in the original DataFrame\n",
        "print(\"NaN values in original DataFrame:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Drop rows with NaN values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Check if the dataset is empty after dropping NaN values\n",
        "if len(df) == 0:\n",
        "    print(\"Dataset is empty after dropping NaN values. Adjust the data or preprocessing steps.\")\n",
        "    exit()\n",
        "\n",
        "# Fill NaN values in the 'text' column with an empty string\n",
        "df['text'].fillna('', inplace=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['causal_text'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Apply the classifier to the entire dataset\n",
        "X_vec = vectorizer.transform(df['text'])\n",
        "df['predicted_causal_relation'] = classifier.predict(X_vec)\n",
        "\n",
        "# Save the updated dataset\n",
        "df.to_csv('predicted_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmpRD8FGCcir",
        "outputId": "b6017892-cbf8-43a3-df5b-db1c2e21d811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in original DataFrame:\n",
            "corpus             0\n",
            "doc_id             0\n",
            "sent_id            0\n",
            "eg_id              0\n",
            "index              0\n",
            "text               0\n",
            "causal_text        0\n",
            "num_rs             0\n",
            "causal_relation    0\n",
            "dtype: int64\n",
            "Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNGk0BAzt2j9",
        "outputId": "67f7d6cf-1584-406e-c759-356b03714f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adapters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "1q_HzOTgvOi4",
        "outputId": "b7ac22da-ea4c-4aa0-ece6-e86978be61c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adapters\n",
            "  Downloading adapters-0.1.2-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/256.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers~=4.36.0 (from adapters)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.36.0->adapters) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.36.0->adapters) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.36.0->adapters) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.36.0->adapters) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.36.0->adapters) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.36.0->adapters) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.36.0->adapters) (2024.2.2)\n",
            "Installing collected packages: transformers, adapters\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.39.1\n",
            "    Uninstalling transformers-4.39.1:\n",
            "      Successfully uninstalled transformers-4.39.1\n",
            "Successfully installed adapters-0.1.2 transformers-4.36.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "99e9b051c42b474a9219b4416ba94383"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from awq import AutoAWQForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers.adapters.composition import Fuse\n",
        "\n",
        "model_name_or_path = \"TheBloke/zephyr-7B-beta-AWQ\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
        "# Load model\n",
        "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,\n",
        "                                          trust_remote_code=False, safetensors=True)\n",
        "\n",
        "# Attach trainable adapter to the model\n",
        "adapter_setup = Fuse.load(\"pfeiffer+inv\", AdapterType.text_task)\n",
        "model.add_adapter(\"economic_events\", AdapterType.text_task)\n",
        "model.train_adapter([\"economic_events\"])\n",
        "\n",
        "# Define a few-shot learning dataset\n",
        "few_shot_examples = {\n",
        "    'economic_events': [\n",
        "        \"Cause: A decrease in interest rates.\",\n",
        "        \"Signal: Leads to.\",\n",
        "        \"Effect: Increased borrowing and spending by consumers.\"\n",
        "    ],\n",
        "    'natural_disasters': [\n",
        "        \"Cause: Earthquake.\",\n",
        "        \"Signal: Causes.\",\n",
        "        \"Effect: Destruction of buildings and infrastructure.\"\n",
        "    ],\n",
        "    # Add examples for other domains...\n",
        "}\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, examples, max_length=128):\n",
        "        self.examples = examples\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "\n",
        "# Prepare datasets\n",
        "datasets = {}\n",
        "for domain, examples in few_shot_examples.items():\n",
        "    datasets[domain] = CustomDataset(tokenizer, examples)\n",
        "\n",
        "# Fine-tune the model on the few-shot examples\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        "    save_steps=1000,\n",
        "    output_dir='./output',\n",
        "    overwrite_output_dir=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "for domain, dataset in datasets.items():\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        "        train_dataset=dataset,\n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "# Generate more examples based on few-shot learning\n",
        "def generate_examples(domain, num_examples=5, prompt=[]):\n",
        "    # Generate examples based on prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=50, truncation=True)\n",
        "    outputs = model.generate(inputs.input_ids, max_length=100, num_return_sequences=num_examples, temperature=0.7)\n",
        "\n",
        "    generated_examples = []\n",
        "    for output in outputs:\n",
        "        text = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        generated_examples.append(text)\n",
        "\n",
        "    return generated_examples\n",
        "\n",
        "# Example usage:\n",
        "domain = 'economic_events'\n",
        "prompt = [\n",
        "    \"Cause: Changes in government policies.\",\n",
        "    \"Signal: May result in.\",\n",
        "    \"Effect:\"\n",
        "]\n",
        "generated_examples = generate_examples(domain, num_examples=5, prompt=prompt)\n",
        "for example in generated_examples:\n",
        "    print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "EvXdu5jksuvp",
        "outputId": "e9525003-755f-4fce-cc72-6ce687d35ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers.models.gemma'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5a8a282033e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TheBloke/zephyr-7B-beta-AWQ\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.2.4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmpt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMptAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfalcon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFalconAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbloom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBloomAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/models/mpt.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseAWQForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_mpt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMptBlock\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mOldMptBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMptForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMptAWQForCausalLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseAWQForCausalLM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/models/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAwqConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mScaledActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAwqQuantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_named_linears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_op_by_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/quantize/quantizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalib_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_calib_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mawq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_best_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m from awq.modules.linear import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/quantize/scale.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbloom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_bloom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBloomGelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllama\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_llama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaRMSNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_gemma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGemmaRMSNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNewGELUActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPytorchGELUTanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGELUActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.gemma'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}